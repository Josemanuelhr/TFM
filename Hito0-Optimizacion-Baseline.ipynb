{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HITO 0\n",
    "\n",
    "En este cuaderno se realizará la optimización del modelo Deep Learning que será usado durante el TFM.\n",
    "Para la optimización se empleará 5-fold cv y hyperparameter search para el dataset compuesto por los datos de los 21 sujetos (Centralizado).\n",
    "\n",
    "Se explorará la mejor combinación de hiperparámetros mediante optimización bayesiana (https://www.analyticsvidhya.com/blog/2021/05/bayesian-optimization-bayes_opt-or-hyperopt/)\n",
    "\n",
    "Una vez encontrado el mejor modelo, se entrenarán de los modelos 'baseline' sin federated learning para cada sujeto (individuales), por empresa y centralizado. Se medirá el accuracy y el f1-score de cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pickle\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "def prepare_model_data(client_file):\n",
    "    df = pd.read_csv(client_file)\n",
    "    \n",
    "    train, test = train_test_split(df, test_size=0.30, random_state=42)\n",
    "    \n",
    "    X_train = train[['psd_delta', 'psd_theta', 'psd_alpha', 'psd_beta', 'psd_gamma','eog_blinks', 'eog_var']]\n",
    "    X_test = test[['psd_delta', 'psd_theta', 'psd_alpha', 'psd_beta', 'psd_gamma','eog_blinks', 'eog_var']]\n",
    "    y_train = train['y_class']\n",
    "    y_test = test['y_class']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el dataset de los 21 sujetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e1 = os.listdir(\"./data/horizontal/empresa_1/\")\n",
    "e2 = os.listdir(\"./data/horizontal/empresa_2/\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_model_data(f'./data/horizontal/empresa_2/{e2[0]}')\n",
    "\n",
    "\n",
    "for file in e1:\n",
    "    path = f'./data/horizontal/empresa_1/{file}'\n",
    "    X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "    X_train = np.vstack((X_train, X_train_act))\n",
    "    X_val = np.vstack((X_val, X_val_act))\n",
    "    y_train = np.concatenate((y_train, y_train_act))\n",
    "    y_val = np.concatenate((y_val, y_val_act))\n",
    "    \n",
    "for file in e2[1:]:\n",
    "    path = f'./data/horizontal/empresa_2/{file}'\n",
    "    X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "    X_train = np.vstack((X_train, X_train_act))\n",
    "    X_val = np.vstack((X_val, X_val_act))\n",
    "    y_train = np.concatenate((y_train, y_train_act))\n",
    "    y_val = np.concatenate((y_val, y_val_act))\n",
    "    \n",
    "# y_train = y_train.astype(int)\n",
    "# y_val = y_val.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Búsqueda del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set seed\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(123) \n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create function\n",
    "def nn_cl_bo2(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2, normalization, dropout, dropout_rate):\n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "        \n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "        \n",
    "    neurons = round(neurons)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "        \n",
    "    def nn_cl_fun():\n",
    "        input_shape = (7, )\n",
    "        \n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(neurons, input_shape=input_shape, activation=activation))\n",
    "        if normalization > 0.5:\n",
    "            nn.add(BatchNormalization())\n",
    "        for i in range(layers1):\n",
    "            nn.add(Dense(neurons, activation=activation))\n",
    "        if dropout > 0.5:\n",
    "            nn.add(Dropout(dropout_rate, seed=123))\n",
    "        for i in range(layers2):\n",
    "            nn.add(Dense(neurons, activation=activation))\n",
    "        nn.add(Dense(1, activation='sigmoid'))\n",
    "        nn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return nn\n",
    "        \n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
    "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 5.51    \u001b[0m | \u001b[0m 56.58   \u001b[0m | \u001b[0m 0.4361  \u001b[0m | \u001b[0m 0.2308  \u001b[0m | \u001b[0m 65.44   \u001b[0m | \u001b[0m 1.298   \u001b[0m | \u001b[0m 1.045   \u001b[0m | \u001b[0m 0.4208  \u001b[0m | \u001b[0m 42.9    \u001b[0m | \u001b[0m 0.3377  \u001b[0m | \u001b[0m 6.935   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 2.14    \u001b[0m | \u001b[0m 35.49   \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 0.1864  \u001b[0m | \u001b[0m 62.91   \u001b[0m | \u001b[0m 1.932   \u001b[0m | \u001b[0m 1.237   \u001b[0m | \u001b[0m 0.07488 \u001b[0m | \u001b[0m 92.56   \u001b[0m | \u001b[0m 0.794   \u001b[0m | \u001b[0m 5.884   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4123  \u001b[0m | \u001b[0m 7.337   \u001b[0m | \u001b[0m 253.8   \u001b[0m | \u001b[0m 0.5773  \u001b[0m | \u001b[0m 0.2441  \u001b[0m | \u001b[0m 80.56   \u001b[0m | \u001b[0m 1.055   \u001b[0m | \u001b[0m 1.908   \u001b[0m | \u001b[0m 0.1062  \u001b[0m | \u001b[0m 86.29   \u001b[0m | \u001b[0m 0.6977  \u001b[0m | \u001b[0m 3.957   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 2.468   \u001b[0m | \u001b[0m 255.6   \u001b[0m | \u001b[0m 0.138   \u001b[0m | \u001b[0m 0.1846  \u001b[0m | \u001b[0m 88.2    \u001b[0m | \u001b[0m 1.81    \u001b[0m | \u001b[0m 2.456   \u001b[0m | \u001b[0m 0.3235  \u001b[0m | \u001b[0m 55.04   \u001b[0m | \u001b[0m 0.319   \u001b[0m | \u001b[0m 6.631   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7232  \u001b[0m | \u001b[95m 8.268   \u001b[0m | \u001b[95m 211.3   \u001b[0m | \u001b[95m 0.03408 \u001b[0m | \u001b[95m 0.283   \u001b[0m | \u001b[95m 144.1   \u001b[0m | \u001b[95m 2.613   \u001b[0m | \u001b[95m 1.963   \u001b[0m | \u001b[95m 0.9668  \u001b[0m | \u001b[95m 56.27   \u001b[0m | \u001b[95m 0.3188  \u001b[0m | \u001b[95m 0.1151  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.7445  \u001b[0m | \u001b[95m 0.3436  \u001b[0m | \u001b[95m 28.74   \u001b[0m | \u001b[95m 0.128   \u001b[0m | \u001b[95m 0.01001 \u001b[0m | \u001b[95m 57.17   \u001b[0m | \u001b[95m 2.088   \u001b[0m | \u001b[95m 1.357   \u001b[0m | \u001b[95m 0.1802  \u001b[0m | \u001b[95m 36.22   \u001b[0m | \u001b[95m 0.683   \u001b[0m | \u001b[95m 3.283   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.4123  \u001b[0m | \u001b[0m 6.914   \u001b[0m | \u001b[0m 176.5   \u001b[0m | \u001b[0m 0.4413  \u001b[0m | \u001b[0m 0.1786  \u001b[0m | \u001b[0m 85.4    \u001b[0m | \u001b[0m 2.927   \u001b[0m | \u001b[0m 1.296   \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 62.34   \u001b[0m | \u001b[0m 0.5925  \u001b[0m | \u001b[0m 4.793   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7141  \u001b[0m | \u001b[0m 1.597   \u001b[0m | \u001b[0m 223.5   \u001b[0m | \u001b[0m 0.4821  \u001b[0m | \u001b[0m 0.0208  \u001b[0m | \u001b[0m 73.77   \u001b[0m | \u001b[0m 1.723   \u001b[0m | \u001b[0m 1.944   \u001b[0m | \u001b[0m 0.1803  \u001b[0m | \u001b[0m 38.15   \u001b[0m | \u001b[0m 0.9491  \u001b[0m | \u001b[0m 4.59    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5526  \u001b[0m | \u001b[0m 1.215   \u001b[0m | \u001b[0m 238.7   \u001b[0m | \u001b[0m 0.8418  \u001b[0m | \u001b[0m 0.01583 \u001b[0m | \u001b[0m 54.44   \u001b[0m | \u001b[0m 2.745   \u001b[0m | \u001b[0m 2.348   \u001b[0m | \u001b[0m 0.298   \u001b[0m | \u001b[0m 80.08   \u001b[0m | \u001b[0m 0.6183  \u001b[0m | \u001b[0m 1.473   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.4123  \u001b[0m | \u001b[0m 7.219   \u001b[0m | \u001b[0m 30.19   \u001b[0m | \u001b[0m 0.3082  \u001b[0m | \u001b[0m 0.06221 \u001b[0m | \u001b[0m 146.7   \u001b[0m | \u001b[0m 2.819   \u001b[0m | \u001b[0m 2.353   \u001b[0m | \u001b[0m 0.1161  \u001b[0m | \u001b[0m 96.85   \u001b[0m | \u001b[0m 0.09171 \u001b[0m | \u001b[0m 4.409   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.7454  \u001b[0m | \u001b[95m 8.126   \u001b[0m | \u001b[95m 97.55   \u001b[0m | \u001b[95m 0.6528  \u001b[0m | \u001b[95m 0.2775  \u001b[0m | \u001b[95m 74.88   \u001b[0m | \u001b[95m 2.543   \u001b[0m | \u001b[95m 2.792   \u001b[0m | \u001b[95m 0.6206  \u001b[0m | \u001b[95m 36.33   \u001b[0m | \u001b[95m 0.3749  \u001b[0m | \u001b[95m 4.451   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 4.132   \u001b[0m | \u001b[0m 143.7   \u001b[0m | \u001b[0m 0.3523  \u001b[0m | \u001b[0m 0.198   \u001b[0m | \u001b[0m 87.18   \u001b[0m | \u001b[0m 1.909   \u001b[0m | \u001b[0m 1.25    \u001b[0m | \u001b[0m 0.4131  \u001b[0m | \u001b[0m 45.48   \u001b[0m | \u001b[0m 0.3467  \u001b[0m | \u001b[0m 6.821   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6858  \u001b[0m | \u001b[0m 1.94    \u001b[0m | \u001b[0m 179.9   \u001b[0m | \u001b[0m 0.03181 \u001b[0m | \u001b[0m 0.2506  \u001b[0m | \u001b[0m 114.2   \u001b[0m | \u001b[0m 2.932   \u001b[0m | \u001b[0m 2.184   \u001b[0m | \u001b[0m 0.2181  \u001b[0m | \u001b[0m 78.94   \u001b[0m | \u001b[0m 0.03087 \u001b[0m | \u001b[0m 2.931   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6426  \u001b[0m | \u001b[0m 2.531   \u001b[0m | \u001b[0m 41.5    \u001b[0m | \u001b[0m 0.4263  \u001b[0m | \u001b[0m 0.2522  \u001b[0m | \u001b[0m 43.25   \u001b[0m | \u001b[0m 2.973   \u001b[0m | \u001b[0m 1.467   \u001b[0m | \u001b[0m 0.7217  \u001b[0m | \u001b[0m 74.57   \u001b[0m | \u001b[0m 0.07776 \u001b[0m | \u001b[0m 4.881   \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.7547  \u001b[0m | \u001b[95m 2.388   \u001b[0m | \u001b[95m 232.4   \u001b[0m | \u001b[95m 0.8183  \u001b[0m | \u001b[95m 0.1198  \u001b[0m | \u001b[95m 128.4   \u001b[0m | \u001b[95m 1.396   \u001b[0m | \u001b[95m 2.045   \u001b[0m | \u001b[95m 0.4131  \u001b[0m | \u001b[95m 94.44   \u001b[0m | \u001b[95m 0.8254  \u001b[0m | \u001b[95m 3.507   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6989  \u001b[0m | \u001b[0m 1.051   \u001b[0m | \u001b[0m 18.78   \u001b[0m | \u001b[0m 0.9132  \u001b[0m | \u001b[0m 0.1537  \u001b[0m | \u001b[0m 131.2   \u001b[0m | \u001b[0m 1.19    \u001b[0m | \u001b[0m 2.607   \u001b[0m | \u001b[0m 0.06317 \u001b[0m | \u001b[0m 72.66   \u001b[0m | \u001b[0m 0.9688  \u001b[0m | \u001b[0m 2.782   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5526  \u001b[0m | \u001b[0m 5.936   \u001b[0m | \u001b[0m 67.57   \u001b[0m | \u001b[0m 0.8899  \u001b[0m | \u001b[0m 0.296   \u001b[0m | \u001b[0m 118.6   \u001b[0m | \u001b[0m 2.283   \u001b[0m | \u001b[0m 1.504   \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 45.1    \u001b[0m | \u001b[0m 0.8683  \u001b[0m | \u001b[0m 1.868   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5952  \u001b[0m | \u001b[0m 8.757   \u001b[0m | \u001b[0m 67.25   \u001b[0m | \u001b[0m 0.2978  \u001b[0m | \u001b[0m 0.221   \u001b[0m | \u001b[0m 31.55   \u001b[0m | \u001b[0m 1.06    \u001b[0m | \u001b[0m 2.468   \u001b[0m | \u001b[0m 0.4988  \u001b[0m | \u001b[0m 41.36   \u001b[0m | \u001b[0m 0.00893 \u001b[0m | \u001b[0m 5.955   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7536  \u001b[0m | \u001b[0m 4.828   \u001b[0m | \u001b[0m 189.6   \u001b[0m | \u001b[0m 0.6616  \u001b[0m | \u001b[0m 0.2516  \u001b[0m | \u001b[0m 76.58   \u001b[0m | \u001b[0m 1.852   \u001b[0m | \u001b[0m 2.656   \u001b[0m | \u001b[0m 0.4695  \u001b[0m | \u001b[0m 86.5    \u001b[0m | \u001b[0m 0.01418 \u001b[0m | \u001b[0m 2.777   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.4474  \u001b[0m | \u001b[0m 1.155   \u001b[0m | \u001b[0m 44.34   \u001b[0m | \u001b[0m 0.206   \u001b[0m | \u001b[0m 0.2243  \u001b[0m | \u001b[0m 141.6   \u001b[0m | \u001b[0m 1.761   \u001b[0m | \u001b[0m 1.921   \u001b[0m | \u001b[0m 0.8735  \u001b[0m | \u001b[0m 86.09   \u001b[0m | \u001b[0m 0.02497 \u001b[0m | \u001b[0m 6.111   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5526  \u001b[0m | \u001b[0m 5.441   \u001b[0m | \u001b[0m 139.9   \u001b[0m | \u001b[0m 0.5893  \u001b[0m | \u001b[0m 0.2399  \u001b[0m | \u001b[0m 50.79   \u001b[0m | \u001b[0m 1.374   \u001b[0m | \u001b[0m 1.516   \u001b[0m | \u001b[0m 0.05202 \u001b[0m | \u001b[0m 66.45   \u001b[0m | \u001b[0m 0.3518  \u001b[0m | \u001b[0m 6.419   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7529  \u001b[0m | \u001b[0m 4.289   \u001b[0m | \u001b[0m 41.09   \u001b[0m | \u001b[0m 0.1525  \u001b[0m | \u001b[0m 0.08206 \u001b[0m | \u001b[0m 123.8   \u001b[0m | \u001b[0m 1.786   \u001b[0m | \u001b[0m 2.598   \u001b[0m | \u001b[0m 0.4336  \u001b[0m | \u001b[0m 31.12   \u001b[0m | \u001b[0m 0.01064 \u001b[0m | \u001b[0m 3.016   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7045  \u001b[0m | \u001b[0m 5.966   \u001b[0m | \u001b[0m 139.6   \u001b[0m | \u001b[0m 0.5801  \u001b[0m | \u001b[0m 0.1479  \u001b[0m | \u001b[0m 118.9   \u001b[0m | \u001b[0m 2.579   \u001b[0m | \u001b[0m 2.562   \u001b[0m | \u001b[0m 0.1284  \u001b[0m | \u001b[0m 95.51   \u001b[0m | \u001b[0m 0.8777  \u001b[0m | \u001b[0m 4.897   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6355  \u001b[0m | \u001b[0m 8.432   \u001b[0m | \u001b[0m 177.7   \u001b[0m | \u001b[0m 0.5944  \u001b[0m | \u001b[0m 0.1035  \u001b[0m | \u001b[0m 40.03   \u001b[0m | \u001b[0m 2.159   \u001b[0m | \u001b[0m 1.035   \u001b[0m | \u001b[0m 0.5529  \u001b[0m | \u001b[0m 72.44   \u001b[0m | \u001b[0m 0.6784  \u001b[0m | \u001b[0m 1.194   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.5632  \u001b[0m | \u001b[0m 5.194   \u001b[0m | \u001b[0m 65.43   \u001b[0m | \u001b[0m 0.2515  \u001b[0m | \u001b[0m 0.2908  \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 1.246   \u001b[0m | \u001b[0m 2.762   \u001b[0m | \u001b[0m 0.948   \u001b[0m | \u001b[0m 59.49   \u001b[0m | \u001b[0m 0.413   \u001b[0m | \u001b[0m 4.04    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6322  \u001b[0m | \u001b[0m 3.395   \u001b[0m | \u001b[0m 193.7   \u001b[0m | \u001b[0m 0.7905  \u001b[0m | \u001b[0m 0.2952  \u001b[0m | \u001b[0m 75.48   \u001b[0m | \u001b[0m 1.34    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.1927  \u001b[0m | \u001b[0m 99.32   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.451   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7371  \u001b[0m | \u001b[0m 2.817   \u001b[0m | \u001b[0m 234.4   \u001b[0m | \u001b[0m 0.5911  \u001b[0m | \u001b[0m 0.1272  \u001b[0m | \u001b[0m 129.0   \u001b[0m | \u001b[0m 1.775   \u001b[0m | \u001b[0m 2.877   \u001b[0m | \u001b[0m 0.2106  \u001b[0m | \u001b[0m 95.89   \u001b[0m | \u001b[0m 0.6705  \u001b[0m | \u001b[0m 3.308   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5527  \u001b[0m | \u001b[0m 4.815   \u001b[0m | \u001b[0m 224.4   \u001b[0m | \u001b[0m 0.3793  \u001b[0m | \u001b[0m 0.1875  \u001b[0m | \u001b[0m 134.7   \u001b[0m | \u001b[0m 2.102   \u001b[0m | \u001b[0m 2.491   \u001b[0m | \u001b[0m 0.506   \u001b[0m | \u001b[0m 80.63   \u001b[0m | \u001b[0m 0.5308  \u001b[0m | \u001b[0m 2.09    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 228.2   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.00354 \u001b[0m | \u001b[0m 119.9   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 99.87   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 6.205   \u001b[0m |\n",
      "=============================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "params_nn2 ={\n",
    "    'neurons': (25, 100),\n",
    "    'activation':(0, 9),\n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.001, 1),\n",
    "    'batch_size':(16, 256),\n",
    "    'epochs':(30, 150),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,3),\n",
    "    'normalization':(0,1),\n",
    "    'dropout':(0,1),\n",
    "    'dropout_rate':(0,0.3)\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "nn_bo = BayesianOptimization(nn_cl_bo2, params_nn2, random_state=111)\n",
    "nn_bo.maximize(init_points=25, n_iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softplus',\n",
       " 'batch_size': 232,\n",
       " 'dropout': 0.8182638736220813,\n",
       " 'dropout_rate': 0.11976995858293202,\n",
       " 'epochs': 128,\n",
       " 'layers1': 1,\n",
       " 'layers2': 2,\n",
       " 'learning_rate': 0.41306235723522167,\n",
       " 'neurons': 94,\n",
       " 'normalization': 0.8253804525121795,\n",
       " 'optimizer': <keras.optimizer_v2.adagrad.Adagrad at 0x1cd266526a0>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_nn_ = nn_bo.max['params']\n",
    "\n",
    "learning_rate = params_nn_['learning_rate']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential', LeakyReLU,'relu']\n",
    "params_nn_['activation'] = activationL[round(params_nn_['activation'])]\n",
    "\n",
    "params_nn_['batch_size'] = round(params_nn_['batch_size'])\n",
    "params_nn_['epochs'] = round(params_nn_['epochs'])\n",
    "params_nn_['layers1'] = round(params_nn_['layers1'])\n",
    "params_nn_['layers2'] = round(params_nn_['layers2'])\n",
    "params_nn_['neurons'] = round(params_nn_['neurons'])\n",
    "\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\n",
    "optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "             'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "             'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "             'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "params_nn_['optimizer'] = optimizerD[optimizerL[round(params_nn_['optimizer'])]]\n",
    "\n",
    "params_nn_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura\n",
    "Input -> 1 Dense -> IF normalization > 0.5 BatchNorm -> layers1 Dense -> IF dropout > 0.5 Dropout -> layers2 Dense -> Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se almacenan los resultados para poder consultarlos posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.5877264325323475,\n",
       "  'params': {'activation': 5.509531580558568,\n",
       "   'batch_size': 56.57674104295274,\n",
       "   'dropout': 0.4360590193711702,\n",
       "   'dropout_rate': 0.23077874175693686,\n",
       "   'epochs': 65.43903652834514,\n",
       "   'layers1': 1.2983259142789796,\n",
       "   'layers2': 1.0449566490883235,\n",
       "   'learning_rate': 0.4208042677722932,\n",
       "   'neurons': 42.90116059348345,\n",
       "   'normalization': 0.33765619188879237,\n",
       "   'optimizer': 6.934987252416151}},\n",
       " {'target': 0.5877264325323475,\n",
       "  'params': {'activation': 2.139538085100205,\n",
       "   'batch_size': 35.486238268290776,\n",
       "   'dropout': 0.6696002382466298,\n",
       "   'dropout_rate': 0.1863728758202091,\n",
       "   'epochs': 62.91042362478221,\n",
       "   'layers1': 1.9324428197899461,\n",
       "   'layers2': 1.2367355022465671,\n",
       "   'learning_rate': 0.074883606579061,\n",
       "   'neurons': 92.55806343705127,\n",
       "   'normalization': 0.7939625604796284,\n",
       "   'optimizer': 5.883987541069969}},\n",
       " {'target': 0.4122735674676525,\n",
       "  'params': {'activation': 7.336867117076466,\n",
       "   'batch_size': 253.82916431929843,\n",
       "   'dropout': 0.5772738296076794,\n",
       "   'dropout_rate': 0.2441300751109463,\n",
       "   'epochs': 80.55814528790626,\n",
       "   'layers1': 1.0548959196263075,\n",
       "   'layers2': 1.9082732863169398,\n",
       "   'learning_rate': 0.10622075922977804,\n",
       "   'neurons': 86.29150461662434,\n",
       "   'normalization': 0.6977277345956326,\n",
       "   'optimizer': 3.9569978093780853}},\n",
       " {'target': 0.5877264325323475,\n",
       "  'params': {'activation': 2.468045659036608,\n",
       "   'batch_size': 255.63369848551585,\n",
       "   'dropout': 0.13804205305593598,\n",
       "   'dropout_rate': 0.1846247062404367,\n",
       "   'epochs': 88.2043561006119,\n",
       "   'layers1': 1.8100540717866136,\n",
       "   'layers2': 2.455698193003047,\n",
       "   'learning_rate': 0.3234911115589054,\n",
       "   'neurons': 55.04091624375888,\n",
       "   'normalization': 0.3189664036607044,\n",
       "   'optimizer': 6.630552805747791}},\n",
       " {'target': 0.7231792975970425,\n",
       "  'params': {'activation': 8.268375260379909,\n",
       "   'batch_size': 211.32265070086837,\n",
       "   'dropout': 0.03407709152060179,\n",
       "   'dropout_rate': 0.28301186074348944,\n",
       "   'epochs': 144.05269978986013,\n",
       "   'layers1': 2.6131821012463528,\n",
       "   'layers2': 1.962556084406021,\n",
       "   'learning_rate': 0.9667924668704769,\n",
       "   'neurons': 56.273431329774084,\n",
       "   'normalization': 0.3188401259211743,\n",
       "   'optimizer': 0.11509972323093853}},\n",
       " {'target': 0.744547134935305,\n",
       "  'params': {'activation': 0.34363733115126405,\n",
       "   'batch_size': 28.741516106797608,\n",
       "   'dropout': 0.1279608146375314,\n",
       "   'dropout_rate': 0.010014947837176436,\n",
       "   'epochs': 57.1705310879442,\n",
       "   'layers1': 2.0878178106305225,\n",
       "   'layers2': 1.3572516199744031,\n",
       "   'learning_rate': 0.18016543908216745,\n",
       "   'neurons': 36.220991180194794,\n",
       "   'normalization': 0.6830131255680931,\n",
       "   'optimizer': 3.2830598543419187}},\n",
       " {'target': 0.4122735674676525,\n",
       "  'params': {'activation': 6.914231378130863,\n",
       "   'batch_size': 176.5153740561008,\n",
       "   'dropout': 0.4412681772565863,\n",
       "   'dropout_rate': 0.1785676351323205,\n",
       "   'epochs': 85.39879425205544,\n",
       "   'layers1': 2.9265337459489063,\n",
       "   'layers2': 1.2956227581269149,\n",
       "   'learning_rate': 0.9069063138396268,\n",
       "   'neurons': 62.34436270749121,\n",
       "   'normalization': 0.5924984671923367,\n",
       "   'optimizer': 4.792605915345409}},\n",
       " {'target': 0.7140850277264325,\n",
       "  'params': {'activation': 1.5970559761063947,\n",
       "   'batch_size': 223.52451689122285,\n",
       "   'dropout': 0.4820887768136817,\n",
       "   'dropout_rate': 0.020802538234812772,\n",
       "   'epochs': 73.76776032540891,\n",
       "   'layers1': 1.7230083866445973,\n",
       "   'layers2': 1.9441269990548293,\n",
       "   'learning_rate': 0.18030536285997933,\n",
       "   'neurons': 38.14598802908271,\n",
       "   'normalization': 0.9491296024792569,\n",
       "   'optimizer': 4.589776203856763}},\n",
       " {'target': 0.5526062846580407,\n",
       "  'params': {'activation': 1.2149597837165236,\n",
       "   'batch_size': 238.66859828371702,\n",
       "   'dropout': 0.8417916174207136,\n",
       "   'dropout_rate': 0.015832810724624568,\n",
       "   'epochs': 54.44202208096932,\n",
       "   'layers1': 2.7450032770743427,\n",
       "   'layers2': 2.347696127921317,\n",
       "   'learning_rate': 0.2979752376120147,\n",
       "   'neurons': 80.08098090345707,\n",
       "   'normalization': 0.6183402708174415,\n",
       "   'optimizer': 1.473494720695772}},\n",
       " {'target': 0.4122735674676525,\n",
       "  'params': {'activation': 7.218581194677919,\n",
       "   'batch_size': 30.185699494709503,\n",
       "   'dropout': 0.3082233049139541,\n",
       "   'dropout_rate': 0.06221024811200568,\n",
       "   'epochs': 146.6628994559709,\n",
       "   'layers1': 2.818837162387905,\n",
       "   'layers2': 2.3529083855440005,\n",
       "   'learning_rate': 0.11607091779763729,\n",
       "   'neurons': 96.84855096325721,\n",
       "   'normalization': 0.0917133238506993,\n",
       "   'optimizer': 4.408575266621831}},\n",
       " {'target': 0.7453604436229205,\n",
       "  'params': {'activation': 8.126104897104005,\n",
       "   'batch_size': 97.5513466391215,\n",
       "   'dropout': 0.6528042918753562,\n",
       "   'dropout_rate': 0.27754755457150737,\n",
       "   'epochs': 74.87802029105968,\n",
       "   'layers1': 2.5427283520890556,\n",
       "   'layers2': 2.7923294515041857,\n",
       "   'learning_rate': 0.6205579105630729,\n",
       "   'neurons': 36.329505556369455,\n",
       "   'normalization': 0.37491974612014767,\n",
       "   'optimizer': 4.450883884530945}},\n",
       " {'target': 0.5877264325323475,\n",
       "  'params': {'activation': 4.1316365824189045,\n",
       "   'batch_size': 143.73716056302902,\n",
       "   'dropout': 0.3522921819565613,\n",
       "   'dropout_rate': 0.19795858847194006,\n",
       "   'epochs': 87.18281170006405,\n",
       "   'layers1': 1.9091898874580666,\n",
       "   'layers2': 1.2495950593153025,\n",
       "   'learning_rate': 0.41305976427083396,\n",
       "   'neurons': 45.48217917501583,\n",
       "   'normalization': 0.34674087903714457,\n",
       "   'optimizer': 6.820620055674295}},\n",
       " {'target': 0.6858410351201478,\n",
       "  'params': {'activation': 1.940225300823559,\n",
       "   'batch_size': 179.8822983456297,\n",
       "   'dropout': 0.03180999373346571,\n",
       "   'dropout_rate': 0.2506148814963924,\n",
       "   'epochs': 114.19828127245748,\n",
       "   'layers1': 2.9318875542112344,\n",
       "   'layers2': 2.1836324210231686,\n",
       "   'learning_rate': 0.2181280757716714,\n",
       "   'neurons': 78.94196765025778,\n",
       "   'normalization': 0.03086998935684493,\n",
       "   'optimizer': 2.9309556676140867}},\n",
       " {'target': 0.6425878003696858,\n",
       "  'params': {'activation': 2.5310260724112066,\n",
       "   'batch_size': 41.498646206825654,\n",
       "   'dropout': 0.4263462177034032,\n",
       "   'dropout_rate': 0.25217325160599263,\n",
       "   'epochs': 43.24936105831199,\n",
       "   'layers1': 2.9733048976012295,\n",
       "   'layers2': 1.4665866494857005,\n",
       "   'learning_rate': 0.7216901639169558,\n",
       "   'neurons': 74.56690205830157,\n",
       "   'normalization': 0.07775670746928676,\n",
       "   'optimizer': 4.880990067313126}},\n",
       " {'target': 0.7546765249537893,\n",
       "  'params': {'activation': 2.3877561918215027,\n",
       "   'batch_size': 232.44120675251253,\n",
       "   'dropout': 0.8182638736220813,\n",
       "   'dropout_rate': 0.11976995858293202,\n",
       "   'epochs': 128.43425087995962,\n",
       "   'layers1': 1.3956301660428805,\n",
       "   'layers2': 2.045050140215233,\n",
       "   'learning_rate': 0.41306235723522167,\n",
       "   'neurons': 94.43753966415451,\n",
       "   'normalization': 0.8253804525121795,\n",
       "   'optimizer': 3.5072077017120886}},\n",
       " {'target': 0.6988539741219963,\n",
       "  'params': {'activation': 1.0511002745882656,\n",
       "   'batch_size': 18.782156841162113,\n",
       "   'dropout': 0.9131504384208619,\n",
       "   'dropout_rate': 0.15371924329624512,\n",
       "   'epochs': 131.16985321068887,\n",
       "   'layers1': 1.1896933895582968,\n",
       "   'layers2': 2.606853235119871,\n",
       "   'learning_rate': 0.06316592415918232,\n",
       "   'neurons': 72.66208579941437,\n",
       "   'normalization': 0.9687811501818422,\n",
       "   'optimizer': 2.782025609069458}},\n",
       " {'target': 0.5526062846580406,\n",
       "  'params': {'activation': 5.936280994025703,\n",
       "   'batch_size': 67.5680166509856,\n",
       "   'dropout': 0.8898656207950376,\n",
       "   'dropout_rate': 0.29598948570788136,\n",
       "   'epochs': 118.64094939521583,\n",
       "   'layers1': 2.282973312308587,\n",
       "   'layers2': 1.504312773558644,\n",
       "   'learning_rate': 0.4763331304894916,\n",
       "   'neurons': 45.104250759883385,\n",
       "   'normalization': 0.8682605508498005,\n",
       "   'optimizer': 1.8682228849147449}},\n",
       " {'target': 0.5951940850277264,\n",
       "  'params': {'activation': 8.757141290778224,\n",
       "   'batch_size': 67.25342782897629,\n",
       "   'dropout': 0.29777470266523465,\n",
       "   'dropout_rate': 0.2210307667883602,\n",
       "   'epochs': 31.546958337973436,\n",
       "   'layers1': 1.0604688759395404,\n",
       "   'layers2': 2.4676466841161115,\n",
       "   'learning_rate': 0.4987586290192581,\n",
       "   'neurons': 41.3550382791297,\n",
       "   'normalization': 0.008929963256854245,\n",
       "   'optimizer': 5.954921196290208}},\n",
       " {'target': 0.7536414048059149,\n",
       "  'params': {'activation': 4.827666592066569,\n",
       "   'batch_size': 189.64169119123224,\n",
       "   'dropout': 0.6615501030781817,\n",
       "   'dropout_rate': 0.25163424049648575,\n",
       "   'epochs': 76.58344175253922,\n",
       "   'layers1': 1.8523623330337355,\n",
       "   'layers2': 2.656259874670268,\n",
       "   'learning_rate': 0.469539828531595,\n",
       "   'neurons': 86.50244624229843,\n",
       "   'normalization': 0.014176936309998611,\n",
       "   'optimizer': 2.777348045039071}},\n",
       " {'target': 0.4473937153419594,\n",
       "  'params': {'activation': 1.1551125970703162,\n",
       "   'batch_size': 44.34091455998475,\n",
       "   'dropout': 0.20598380077371703,\n",
       "   'dropout_rate': 0.2242884882773624,\n",
       "   'epochs': 141.6103466305081,\n",
       "   'layers1': 1.761306891833924,\n",
       "   'layers2': 1.921185201079899,\n",
       "   'learning_rate': 0.8734891858364598,\n",
       "   'neurons': 86.0890829950853,\n",
       "   'normalization': 0.024972639706085875,\n",
       "   'optimizer': 6.1110571185722495}},\n",
       " {'target': 0.5526062846580406,\n",
       "  'params': {'activation': 5.440963357662666,\n",
       "   'batch_size': 139.94518677799542,\n",
       "   'dropout': 0.5892849231130379,\n",
       "   'dropout_rate': 0.23994331589665707,\n",
       "   'epochs': 50.793715251353845,\n",
       "   'layers1': 1.3737292385679833,\n",
       "   'layers2': 1.5163429344928314,\n",
       "   'learning_rate': 0.052015295383710414,\n",
       "   'neurons': 66.44817353099575,\n",
       "   'normalization': 0.35184818333496226,\n",
       "   'optimizer': 6.41891281631166}},\n",
       " {'target': 0.752902033271719,\n",
       "  'params': {'activation': 4.289380718928753,\n",
       "   'batch_size': 41.08910154523397,\n",
       "   'dropout': 0.15252534628981973,\n",
       "   'dropout_rate': 0.08205875143738746,\n",
       "   'epochs': 123.78617267594383,\n",
       "   'layers1': 1.7862199424570013,\n",
       "   'layers2': 2.5977580329945855,\n",
       "   'learning_rate': 0.43363487901592973,\n",
       "   'neurons': 31.116511712296877,\n",
       "   'normalization': 0.010643257301658493,\n",
       "   'optimizer': 3.016191938604442}},\n",
       " {'target': 0.7045471349353051,\n",
       "  'params': {'activation': 5.965531477329643,\n",
       "   'batch_size': 139.6483617474583,\n",
       "   'dropout': 0.5801259080387516,\n",
       "   'dropout_rate': 0.14793085825348554,\n",
       "   'epochs': 118.8586244651988,\n",
       "   'layers1': 2.5788332041251283,\n",
       "   'layers2': 2.562141481171244,\n",
       "   'learning_rate': 0.12841239221836145,\n",
       "   'neurons': 95.51052387842392,\n",
       "   'normalization': 0.8777167752038778,\n",
       "   'optimizer': 4.896564199775872}},\n",
       " {'target': 0.6354898336414049,\n",
       "  'params': {'activation': 8.432056286385619,\n",
       "   'batch_size': 177.708891735969,\n",
       "   'dropout': 0.5944253445746973,\n",
       "   'dropout_rate': 0.10350258012429231,\n",
       "   'epochs': 40.027911600128924,\n",
       "   'layers1': 2.1586800732049714,\n",
       "   'layers2': 1.0352301110206423,\n",
       "   'learning_rate': 0.5528583696052599,\n",
       "   'neurons': 72.44484874852972,\n",
       "   'normalization': 0.6784446665004875,\n",
       "   'optimizer': 1.1936629395700302}},\n",
       " {'target': 0.5631792975970425,\n",
       "  'params': {'activation': 5.193586982056512,\n",
       "   'batch_size': 65.43377070639127,\n",
       "   'dropout': 0.2514767381351549,\n",
       "   'dropout_rate': 0.2907792329718983,\n",
       "   'epochs': 137.59020465886863,\n",
       "   'layers1': 1.2456827044077192,\n",
       "   'layers2': 2.7624760329313465,\n",
       "   'learning_rate': 0.9480331035294425,\n",
       "   'neurons': 59.493593283852626,\n",
       "   'normalization': 0.41295045037025024,\n",
       "   'optimizer': 4.0399911674438655}},\n",
       " {'target': 0.6321626617375231,\n",
       "  'params': {'activation': 3.3949947296194565,\n",
       "   'batch_size': 193.67475938435885,\n",
       "   'dropout': 0.7905247327435551,\n",
       "   'dropout_rate': 0.2952350348319187,\n",
       "   'epochs': 75.47583899016537,\n",
       "   'layers1': 1.339940995943726,\n",
       "   'layers2': 3.0,\n",
       "   'learning_rate': 0.19268226230257493,\n",
       "   'neurons': 99.31631092877326,\n",
       "   'normalization': 0.0,\n",
       "   'optimizer': 1.450581216745689}},\n",
       " {'target': 0.737079482439926,\n",
       "  'params': {'activation': 2.81702460568741,\n",
       "   'batch_size': 234.42754467102083,\n",
       "   'dropout': 0.5911421436934019,\n",
       "   'dropout_rate': 0.12722300282656449,\n",
       "   'epochs': 128.995111681732,\n",
       "   'layers1': 1.7748383702864363,\n",
       "   'layers2': 2.8767613998655905,\n",
       "   'learning_rate': 0.2106461866588223,\n",
       "   'neurons': 95.88844912038701,\n",
       "   'normalization': 0.6704707000027734,\n",
       "   'optimizer': 3.3083161102352148}},\n",
       " {'target': 0.5526802218114603,\n",
       "  'params': {'activation': 4.815344938300972,\n",
       "   'batch_size': 224.40741132890588,\n",
       "   'dropout': 0.37932038467539647,\n",
       "   'dropout_rate': 0.18746531883043835,\n",
       "   'epochs': 134.7322201991356,\n",
       "   'layers1': 2.1020321936439625,\n",
       "   'layers2': 2.4908046582576664,\n",
       "   'learning_rate': 0.5060490330712426,\n",
       "   'neurons': 80.63473318180971,\n",
       "   'normalization': 0.5308121072174533,\n",
       "   'optimizer': 2.089835956893259}},\n",
       " {'target': 0.5877264325323475,\n",
       "  'params': {'activation': 0.0,\n",
       "   'batch_size': 228.2336160771265,\n",
       "   'dropout': 1.0,\n",
       "   'dropout_rate': 0.003540112445815175,\n",
       "   'epochs': 119.92363633259563,\n",
       "   'layers1': 1.0,\n",
       "   'layers2': 1.0,\n",
       "   'learning_rate': 1.0,\n",
       "   'neurons': 99.86572186197874,\n",
       "   'normalization': 1.0,\n",
       "   'optimizer': 6.204936096519717}}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_bo.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results/optimization-python.txt\", \"w\") as f:\n",
    "    for el in nn_bo.res:\n",
    "        f.write(json.dumps(el))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploracion de las mejores combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.5877264325323475,\n",
       " 'params': {'activation': 5.509531580558568,\n",
       "  'batch_size': 56.57674104295274,\n",
       "  'dropout': 0.4360590193711702,\n",
       "  'dropout_rate': 0.23077874175693686,\n",
       "  'epochs': 65.43903652834514,\n",
       "  'layers1': 1.2983259142789796,\n",
       "  'layers2': 1.0449566490883235,\n",
       "  'learning_rate': 0.4208042677722932,\n",
       "  'neurons': 42.90116059348345,\n",
       "  'normalization': 0.33765619188879237,\n",
       "  'optimizer': 6.934987252416151}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./results/optimization-python.txt\", \"r\") as f:\n",
    "    results = []\n",
    "    for line in f.readlines():\n",
    "        results.append(json.loads(line))\n",
    "        \n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>params.activation</th>\n",
       "      <th>params.batch_size</th>\n",
       "      <th>params.dropout</th>\n",
       "      <th>params.dropout_rate</th>\n",
       "      <th>params.epochs</th>\n",
       "      <th>params.layers1</th>\n",
       "      <th>params.layers2</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>params.neurons</th>\n",
       "      <th>params.normalization</th>\n",
       "      <th>params.optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.754677</td>\n",
       "      <td>2.387756</td>\n",
       "      <td>232.441207</td>\n",
       "      <td>0.818264</td>\n",
       "      <td>0.119770</td>\n",
       "      <td>128.434251</td>\n",
       "      <td>1.395630</td>\n",
       "      <td>2.045050</td>\n",
       "      <td>0.413062</td>\n",
       "      <td>94.437540</td>\n",
       "      <td>0.825380</td>\n",
       "      <td>3.507208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.753641</td>\n",
       "      <td>4.827667</td>\n",
       "      <td>189.641691</td>\n",
       "      <td>0.661550</td>\n",
       "      <td>0.251634</td>\n",
       "      <td>76.583442</td>\n",
       "      <td>1.852362</td>\n",
       "      <td>2.656260</td>\n",
       "      <td>0.469540</td>\n",
       "      <td>86.502446</td>\n",
       "      <td>0.014177</td>\n",
       "      <td>2.777348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.752902</td>\n",
       "      <td>4.289381</td>\n",
       "      <td>41.089102</td>\n",
       "      <td>0.152525</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>123.786173</td>\n",
       "      <td>1.786220</td>\n",
       "      <td>2.597758</td>\n",
       "      <td>0.433635</td>\n",
       "      <td>31.116512</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>3.016192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.745360</td>\n",
       "      <td>8.126105</td>\n",
       "      <td>97.551347</td>\n",
       "      <td>0.652804</td>\n",
       "      <td>0.277548</td>\n",
       "      <td>74.878020</td>\n",
       "      <td>2.542728</td>\n",
       "      <td>2.792329</td>\n",
       "      <td>0.620558</td>\n",
       "      <td>36.329506</td>\n",
       "      <td>0.374920</td>\n",
       "      <td>4.450884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.744547</td>\n",
       "      <td>0.343637</td>\n",
       "      <td>28.741516</td>\n",
       "      <td>0.127961</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>57.170531</td>\n",
       "      <td>2.087818</td>\n",
       "      <td>1.357252</td>\n",
       "      <td>0.180165</td>\n",
       "      <td>36.220991</td>\n",
       "      <td>0.683013</td>\n",
       "      <td>3.283060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  params.activation  params.batch_size  params.dropout  \\\n",
       "14  0.754677           2.387756         232.441207        0.818264   \n",
       "18  0.753641           4.827667         189.641691        0.661550   \n",
       "21  0.752902           4.289381          41.089102        0.152525   \n",
       "10  0.745360           8.126105          97.551347        0.652804   \n",
       "5   0.744547           0.343637          28.741516        0.127961   \n",
       "\n",
       "    params.dropout_rate  params.epochs  params.layers1  params.layers2  \\\n",
       "14             0.119770     128.434251        1.395630        2.045050   \n",
       "18             0.251634      76.583442        1.852362        2.656260   \n",
       "21             0.082059     123.786173        1.786220        2.597758   \n",
       "10             0.277548      74.878020        2.542728        2.792329   \n",
       "5              0.010015      57.170531        2.087818        1.357252   \n",
       "\n",
       "    params.learning_rate  params.neurons  params.normalization  \\\n",
       "14              0.413062       94.437540              0.825380   \n",
       "18              0.469540       86.502446              0.014177   \n",
       "21              0.433635       31.116512              0.010643   \n",
       "10              0.620558       36.329506              0.374920   \n",
       "5               0.180165       36.220991              0.683013   \n",
       "\n",
       "    params.optimizer  \n",
       "14          3.507208  \n",
       "18          2.777348  \n",
       "21          3.016192  \n",
       "10          4.450884  \n",
       "5           3.283060  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flatdict\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for r in results:\n",
    "    d = dict(flatdict.FlatDict(r, delimiter='.'))\n",
    "    df = df.append(d, ignore_index=True)\n",
    "\n",
    "df = df.sort_values(by=['target'], ascending=False)\n",
    "df = df[df['target']>0.74]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mayor interpretabilidad, se parsean los resultados a sus valores reales.\n",
    "\n",
    "(Aunque para la posterior definición del modelo se usarán los datos originales.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params.activation</th>\n",
       "      <th>params.optimizer</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>params.epochs</th>\n",
       "      <th>params.batch_size</th>\n",
       "      <th>params.neurons</th>\n",
       "      <th>params.normalization</th>\n",
       "      <th>params.layers1</th>\n",
       "      <th>params.dropout</th>\n",
       "      <th>params.dropout_rate</th>\n",
       "      <th>params.layers2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754677</td>\n",
       "      <td>softplus</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.413062</td>\n",
       "      <td>128.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.119770</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753641</td>\n",
       "      <td>selu</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.469540</td>\n",
       "      <td>77.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.251634</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752902</td>\n",
       "      <td>tanh</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.433635</td>\n",
       "      <td>124.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745360</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.620558</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.277548</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.744547</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.180165</td>\n",
       "      <td>57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy params.activation params.optimizer  params.learning_rate  \\\n",
       "0  0.754677          softplus          Adagrad              0.413062   \n",
       "1  0.753641              selu         Adadelta              0.469540   \n",
       "2  0.752902              tanh         Adadelta              0.433635   \n",
       "3  0.745360         LeakyReLU          Adagrad              0.620558   \n",
       "4  0.744547              relu         Adadelta              0.180165   \n",
       "\n",
       "   params.epochs  params.batch_size  params.neurons params.normalization  \\\n",
       "0          128.0              232.0            94.0                   Si   \n",
       "1           77.0              190.0            87.0                   No   \n",
       "2          124.0               41.0            31.0                   No   \n",
       "3           75.0               98.0            36.0                   No   \n",
       "4           57.0               29.0            36.0                   Si   \n",
       "\n",
       "   params.layers1 params.dropout  params.dropout_rate  params.layers2  \n",
       "0             1.0             Si             0.119770             2.0  \n",
       "1             2.0             Si             0.251634             3.0  \n",
       "2             2.0             No             0.082059             3.0  \n",
       "3             3.0             Si             0.277548             3.0  \n",
       "4             2.0             No             0.010015             1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', 'LeakyReLU','relu']\n",
    "optimizerL = ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','Adam']\n",
    "\n",
    "df_res = pd.DataFrame()\n",
    "\n",
    "for r in df.iterrows():\n",
    "    d = {}\n",
    "    \n",
    "    r = r[1]\n",
    "    d['accuracy'] = r['target']\n",
    "    \n",
    "    d['params.activation'] = activationL[round(r['params.activation'])]\n",
    "    \n",
    "    d['params.optimizer'] = optimizerL[round(r['params.optimizer'])]\n",
    "    d['params.learning_rate'] = r['params.learning_rate']\n",
    "    \n",
    "    d['params.epochs'] = round(r['params.epochs'])\n",
    "    d['params.batch_size'] = round(r['params.batch_size'])\n",
    "    \n",
    "    d['params.neurons'] = round(r['params.neurons'])\n",
    "    \n",
    "    d['params.normalization'] = \"Si\" if r['params.normalization'] > 0.5 else \"No\"\n",
    "    d['params.layers1'] = round(r['params.layers1'])\n",
    "    d['params.dropout'] = \"Si\" if r['params.dropout'] > 0.5 else \"No\"\n",
    "    d['params.dropout_rate'] = r['params.dropout_rate']\n",
    "    d['params.layers2'] = round(r['params.layers2'])\n",
    "    \n",
    "    df_res = df_res.append(d, ignore_index=True)\n",
    "    \n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(123) \n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "Para la medicion del rendimiento de los modelos baseline se incorpora Precision y Recall. También se calculará f1-score a partir de estas dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, TrueNegatives, TruePositives, FalsePositives, FalseNegatives\n",
    "\n",
    "# f1-score: 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones para automatizar el entrenamiento de los modelos\n",
    "\n",
    "- Se crean las funciones para obtener el modelo compilado en base a la configuración de parametros indicada\n",
    "- Se crea la función para entrenar un modelo dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(neurons, activation, optimizer, learning_rate, layers1, layers2, normalization, dropout, dropout_rate):\n",
    "    \n",
    "    ''' LECTURA DE PARAMETROS '''\n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl','SGD']\n",
    "    optimizerD= {'Adam':Adam(lr=learning_rate), 'SGD':SGD(lr=learning_rate),\n",
    "                 'RMSprop':RMSprop(lr=learning_rate), 'Adadelta':Adadelta(lr=learning_rate),\n",
    "                 'Adagrad':Adagrad(lr=learning_rate), 'Adamax':Adamax(lr=learning_rate),\n",
    "                 'Nadam':Nadam(lr=learning_rate), 'Ftrl':Ftrl(lr=learning_rate)}\n",
    "        \n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential', LeakyReLU,'relu']\n",
    "    \n",
    "    neurons = round(neurons)\n",
    "    activation = activationL[round(activation)]\n",
    "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    \n",
    "    ''' DEFINICION DE LA ARQUITECTURA '''\n",
    "    input_shape = (7, )\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(neurons, input_shape=input_shape, activation=activation))\n",
    "    \n",
    "    if normalization > 0.5:\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "    for i in range(layers1):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "        \n",
    "    if dropout > 0.5:\n",
    "        model.add(Dropout(dropout_rate, seed=123))\n",
    "        \n",
    "    for i in range(layers2):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', TruePositives(), TrueNegatives(), FalsePositives(), FalseNegatives()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>params.activation</th>\n",
       "      <th>params.batch_size</th>\n",
       "      <th>params.dropout</th>\n",
       "      <th>params.dropout_rate</th>\n",
       "      <th>params.epochs</th>\n",
       "      <th>params.layers1</th>\n",
       "      <th>params.layers2</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>params.neurons</th>\n",
       "      <th>params.normalization</th>\n",
       "      <th>params.optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.754677</td>\n",
       "      <td>2.387756</td>\n",
       "      <td>232.441207</td>\n",
       "      <td>0.818264</td>\n",
       "      <td>0.119770</td>\n",
       "      <td>128.434251</td>\n",
       "      <td>1.395630</td>\n",
       "      <td>2.045050</td>\n",
       "      <td>0.413062</td>\n",
       "      <td>94.437540</td>\n",
       "      <td>0.825380</td>\n",
       "      <td>3.507208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.753641</td>\n",
       "      <td>4.827667</td>\n",
       "      <td>189.641691</td>\n",
       "      <td>0.661550</td>\n",
       "      <td>0.251634</td>\n",
       "      <td>76.583442</td>\n",
       "      <td>1.852362</td>\n",
       "      <td>2.656260</td>\n",
       "      <td>0.469540</td>\n",
       "      <td>86.502446</td>\n",
       "      <td>0.014177</td>\n",
       "      <td>2.777348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.752902</td>\n",
       "      <td>4.289381</td>\n",
       "      <td>41.089102</td>\n",
       "      <td>0.152525</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>123.786173</td>\n",
       "      <td>1.786220</td>\n",
       "      <td>2.597758</td>\n",
       "      <td>0.433635</td>\n",
       "      <td>31.116512</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>3.016192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.745360</td>\n",
       "      <td>8.126105</td>\n",
       "      <td>97.551347</td>\n",
       "      <td>0.652804</td>\n",
       "      <td>0.277548</td>\n",
       "      <td>74.878020</td>\n",
       "      <td>2.542728</td>\n",
       "      <td>2.792329</td>\n",
       "      <td>0.620558</td>\n",
       "      <td>36.329506</td>\n",
       "      <td>0.374920</td>\n",
       "      <td>4.450884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.744547</td>\n",
       "      <td>0.343637</td>\n",
       "      <td>28.741516</td>\n",
       "      <td>0.127961</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>57.170531</td>\n",
       "      <td>2.087818</td>\n",
       "      <td>1.357252</td>\n",
       "      <td>0.180165</td>\n",
       "      <td>36.220991</td>\n",
       "      <td>0.683013</td>\n",
       "      <td>3.283060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  params.activation  params.batch_size  params.dropout  \\\n",
       "14  0.754677           2.387756         232.441207        0.818264   \n",
       "18  0.753641           4.827667         189.641691        0.661550   \n",
       "21  0.752902           4.289381          41.089102        0.152525   \n",
       "10  0.745360           8.126105          97.551347        0.652804   \n",
       "5   0.744547           0.343637          28.741516        0.127961   \n",
       "\n",
       "    params.dropout_rate  params.epochs  params.layers1  params.layers2  \\\n",
       "14             0.119770     128.434251        1.395630        2.045050   \n",
       "18             0.251634      76.583442        1.852362        2.656260   \n",
       "21             0.082059     123.786173        1.786220        2.597758   \n",
       "10             0.277548      74.878020        2.542728        2.792329   \n",
       "5              0.010015      57.170531        2.087818        1.357252   \n",
       "\n",
       "    params.learning_rate  params.neurons  params.normalization  \\\n",
       "14              0.413062       94.437540              0.825380   \n",
       "18              0.469540       86.502446              0.014177   \n",
       "21              0.433635       31.116512              0.010643   \n",
       "10              0.620558       36.329506              0.374920   \n",
       "5               0.180165       36.220991              0.683013   \n",
       "\n",
       "    params.optimizer  \n",
       "14          3.507208  \n",
       "18          2.777348  \n",
       "21          3.016192  \n",
       "10          4.450884  \n",
       "5           3.283060  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>params.activation</th>\n",
       "      <th>params.optimizer</th>\n",
       "      <th>params.learning_rate</th>\n",
       "      <th>params.epochs</th>\n",
       "      <th>params.batch_size</th>\n",
       "      <th>params.neurons</th>\n",
       "      <th>params.normalization</th>\n",
       "      <th>params.layers1</th>\n",
       "      <th>params.dropout</th>\n",
       "      <th>params.dropout_rate</th>\n",
       "      <th>params.layers2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754677</td>\n",
       "      <td>softplus</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.413062</td>\n",
       "      <td>128.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.119770</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753641</td>\n",
       "      <td>selu</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.469540</td>\n",
       "      <td>77.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.251634</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752902</td>\n",
       "      <td>tanh</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.433635</td>\n",
       "      <td>124.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745360</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.620558</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.277548</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.744547</td>\n",
       "      <td>relu</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.180165</td>\n",
       "      <td>57.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Si</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy params.activation params.optimizer  params.learning_rate  \\\n",
       "0  0.754677          softplus          Adagrad              0.413062   \n",
       "1  0.753641              selu         Adadelta              0.469540   \n",
       "2  0.752902              tanh         Adadelta              0.433635   \n",
       "3  0.745360         LeakyReLU          Adagrad              0.620558   \n",
       "4  0.744547              relu         Adadelta              0.180165   \n",
       "\n",
       "   params.epochs  params.batch_size  params.neurons params.normalization  \\\n",
       "0          128.0              232.0            94.0                   Si   \n",
       "1           77.0              190.0            87.0                   No   \n",
       "2          124.0               41.0            31.0                   No   \n",
       "3           75.0               98.0            36.0                   No   \n",
       "4           57.0               29.0            36.0                   Si   \n",
       "\n",
       "   params.layers1 params.dropout  params.dropout_rate  params.layers2  \n",
       "0             1.0             Si             0.119770             2.0  \n",
       "1             2.0             Si             0.251634             3.0  \n",
       "2             2.0             No             0.082059             3.0  \n",
       "3             3.0             Si             0.277548             3.0  \n",
       "4             2.0             No             0.010015             1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametros entrenables por modelo**\n",
    "- 0: 27,825\n",
    "- 1: 39,064\n",
    "- 2: 5,240\n",
    "- 3: 8,317\n",
    "- 4: 4,393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 36)                288       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 36)               144       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                1332      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 36)                1332      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                1332      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,465\n",
      "Trainable params: 4,393\n",
      "Non-trainable params: 72\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generar_modelo(df, combinacion):\n",
    "    params = dict(df.iloc[combinacion])\n",
    "\n",
    "    model = get_model(neurons = params['params.neurons'],\n",
    "                      activation = params['params.activation'],\n",
    "                      optimizer = params['params.optimizer'],\n",
    "                      learning_rate = params['params.learning_rate'],\n",
    "                      layers1 = params['params.layers1'],\n",
    "                      layers2 = params['params.layers2'],\n",
    "                      normalization = params['params.normalization'],\n",
    "                      dropout = params['params.dropout'],\n",
    "                      dropout_rate = params['params.dropout_rate'])\n",
    "    return model\n",
    "\n",
    "combinacion = 4\n",
    "model = generar_modelo(df, combinacion)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, batch_size = 32, epochs = 150, es = True):\n",
    "    \n",
    "    callbacks = []\n",
    "    if es:\n",
    "        callbacks.append(EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=20, restore_best_weights=True))\n",
    "\n",
    "    hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=0,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks = callbacks)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando cliente 1...\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "Epoch 00113: early stopping\n",
      "{'cliente': 1, 'tp': 219.0, 'tn': 16.0, 'fp': 5.0, 'fn': 13.0}\n",
      "Entrenando cliente 2...\n",
      "Restoring model weights from the end of the best epoch: 118.\n",
      "Epoch 00138: early stopping\n",
      "{'cliente': 2, 'tp': 23.0, 'tn': 209.0, 'fp': 4.0, 'fn': 19.0}\n",
      "Entrenando cliente 3...\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "Epoch 00069: early stopping\n",
      "{'cliente': 3, 'tp': 144.0, 'tn': 71.0, 'fp': 26.0, 'fn': 20.0}\n",
      "Entrenando cliente 4...\n",
      "Restoring model weights from the end of the best epoch: 100.\n",
      "Epoch 00120: early stopping\n",
      "{'cliente': 4, 'tp': 273.0, 'tn': 136.0, 'fp': 57.0, 'fn': 35.0}\n",
      "Entrenando cliente 5...\n",
      "{'cliente': 5, 'tp': 245.0, 'tn': 172.0, 'fp': 27.0, 'fn': 57.0}\n",
      "Entrenando cliente 6...\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 00067: early stopping\n",
      "{'cliente': 6, 'tp': 214.0, 'tn': 6.0, 'fp': 33.0, 'fn': 5.0}\n",
      "Entrenando cliente 7...\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 00067: early stopping\n",
      "{'cliente': 7, 'tp': 168.0, 'tn': 42.0, 'fp': 28.0, 'fn': 15.0}\n",
      "Entrenando cliente 8...\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "Epoch 00095: early stopping\n",
      "{'cliente': 8, 'tp': 47.0, 'tn': 174.0, 'fp': 14.0, 'fn': 26.0}\n",
      "Entrenando cliente 9...\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 00050: early stopping\n",
      "{'cliente': 9, 'tp': 31.0, 'tn': 170.0, 'fp': 4.0, 'fn': 42.0}\n",
      "Entrenando cliente 10...\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "Epoch 00107: early stopping\n",
      "{'cliente': 10, 'tp': 223.0, 'tn': 13.0, 'fp': 25.0, 'fn': 1.0}\n",
      "Entrenando cliente 11...\n",
      "{'cliente': 11, 'tp': 204.0, 'tn': 23.0, 'fp': 15.0, 'fn': 12.0}\n",
      "Entrenando cliente 12...\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Epoch 00087: early stopping\n",
      "{'cliente': 12, 'tp': 146.0, 'tn': 88.0, 'fp': 0.0, 'fn': 10.0}\n",
      "Entrenando cliente 13...\n",
      "Restoring model weights from the end of the best epoch: 116.\n",
      "Epoch 00136: early stopping\n",
      "{'cliente': 13, 'tp': 141.0, 'tn': 86.0, 'fp': 6.0, 'fn': 9.0}\n",
      "Entrenando cliente 14...\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "Epoch 00043: early stopping\n",
      "{'cliente': 14, 'tp': 128.0, 'tn': 55.0, 'fp': 25.0, 'fn': 32.0}\n",
      "Entrenando cliente 15...\n",
      "{'cliente': 15, 'tp': 100.0, 'tn': 121.0, 'fp': 19.0, 'fn': 19.0}\n",
      "Entrenando cliente 16...\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "Epoch 00075: early stopping\n",
      "{'cliente': 16, 'tp': 201.0, 'tn': 41.0, 'fp': 13.0, 'fn': 9.0}\n",
      "Entrenando cliente 17...\n",
      "Restoring model weights from the end of the best epoch: 104.\n",
      "Epoch 00124: early stopping\n",
      "{'cliente': 17, 'tp': 48.0, 'tn': 191.0, 'fp': 2.0, 'fn': 11.0}\n",
      "Entrenando cliente 18...\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "Epoch 00065: early stopping\n",
      "{'cliente': 18, 'tp': 106.0, 'tn': 110.0, 'fp': 2.0, 'fn': 31.0}\n",
      "Entrenando cliente 19...\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "Epoch 00066: early stopping\n",
      "{'cliente': 19, 'tp': 230.0, 'tn': 19.0, 'fp': 14.0, 'fn': 1.0}\n",
      "Entrenando cliente 20...\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "Epoch 00082: early stopping\n",
      "{'cliente': 20, 'tp': 56.0, 'tn': 185.0, 'fp': 3.0, 'fn': 11.0}\n",
      "Entrenando cliente 21...\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "Epoch 00088: early stopping\n",
      "{'cliente': 21, 'tp': 56.0, 'tn': 154.0, 'fp': 5.0, 'fn': 22.0}\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "results = pd.DataFrame(columns=['cliente', 'tp', 'tn', 'fp', 'fn'])\n",
    "\n",
    "base_path = \"./data/horizontal/\"\n",
    "\n",
    "clientes = list(range(1,22))\n",
    "for c in clientes:\n",
    "    print(f\"Entrenando cliente {c}...\")\n",
    "    path = f\"{base_path}empresa_{(c%2)+1}/cliente_{c}.csv\"\n",
    "    X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "    combinacion = 4\n",
    "    model = generar_modelo(df, combinacion)\n",
    "    hist = train_model(model, X_train_act, y_train_act, X_val_act, y_val_act)\n",
    "    \n",
    "    res = hist.model.evaluate(X_val_act, y_val_act, verbose=0)\n",
    "    \n",
    "    tp = res[2]\n",
    "    tn = res[3]\n",
    "    fp = res[4]\n",
    "    fn = res[5]\n",
    "\n",
    "    client_res = {\n",
    "        \"cliente\": int(c),\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn\n",
    "    }\n",
    "    \n",
    "    print(client_res)\n",
    "    \n",
    "    results = results.append(client_res, ignore_index=True)\n",
    "    \n",
    "results.to_csv(\"./results/resultados-modelos-individuales.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando empresa_1...\n",
      "{'empresa': 'empresa_1', 'cliente': '10', 'tp': 170.0, 'tn': 28.0, 'fp': 10.0, 'fn': 54.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '12', 'tp': 143.0, 'tn': 87.0, 'fp': 1.0, 'fn': 13.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '14', 'tp': 126.0, 'tn': 61.0, 'fp': 19.0, 'fn': 34.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '16', 'tp': 197.0, 'tn': 42.0, 'fp': 12.0, 'fn': 13.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '18', 'tp': 112.0, 'tn': 98.0, 'fp': 14.0, 'fn': 25.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '2', 'tp': 38.0, 'tn': 125.0, 'fp': 88.0, 'fn': 4.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '20', 'tp': 55.0, 'tn': 149.0, 'fp': 39.0, 'fn': 12.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '4', 'tp': 249.0, 'tn': 149.0, 'fp': 44.0, 'fn': 59.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '6', 'tp': 206.0, 'tn': 9.0, 'fp': 30.0, 'fn': 13.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '8', 'tp': 44.0, 'tn': 166.0, 'fp': 22.0, 'fn': 29.0}\n",
      "Entrenando empresa_2...\n",
      "{'empresa': 'empresa_2', 'cliente': '1', 'tp': 207.0, 'tn': 16.0, 'fp': 5.0, 'fn': 25.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '11', 'tp': 178.0, 'tn': 17.0, 'fp': 21.0, 'fn': 38.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '13', 'tp': 137.0, 'tn': 58.0, 'fp': 34.0, 'fn': 13.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '15', 'tp': 100.0, 'tn': 105.0, 'fp': 35.0, 'fn': 19.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '17', 'tp': 50.0, 'tn': 143.0, 'fp': 50.0, 'fn': 9.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '19', 'tp': 197.0, 'tn': 22.0, 'fp': 11.0, 'fn': 34.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '21', 'tp': 60.0, 'tn': 145.0, 'fp': 14.0, 'fn': 18.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '3', 'tp': 119.0, 'tn': 71.0, 'fp': 26.0, 'fn': 45.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '5', 'tp': 245.0, 'tn': 158.0, 'fp': 41.0, 'fn': 57.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '7', 'tp': 126.0, 'tn': 53.0, 'fp': 17.0, 'fn': 57.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '9', 'tp': 48.0, 'tn': 140.0, 'fp': 34.0, 'fn': 25.0}\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "results = pd.DataFrame(columns=['empresa', 'cliente', 'tp', 'tn', 'fp', 'fn'])\n",
    "\n",
    "empresas = [\"empresa_1\", \"empresa_2\"]\n",
    "\n",
    "for empresa in empresas:\n",
    "    print(f\"Entrenando {empresa}...\")\n",
    "    clientes = os.listdir(f\"./data/horizontal/{empresa}/\")\n",
    "    \n",
    "    # Dataset de todos los clientes de la empresa\n",
    "    X_train, X_val, y_train, y_val = prepare_model_data(f'./data/horizontal/{empresa}/{clientes[0]}')\n",
    "    \n",
    "    for file in clientes[1:]:\n",
    "        path = f'./data/horizontal/{empresa}/{file}'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "\n",
    "        X_train = np.vstack((X_train, X_train_act))\n",
    "        X_val = np.vstack((X_val, X_val_act))\n",
    "        y_train = np.concatenate((y_train, y_train_act))\n",
    "        y_val = np.concatenate((y_val, y_val_act))\n",
    "    \n",
    "    # Entrenamiento del modelo de la empresa\n",
    "    combinacion = 4\n",
    "    model = generar_modelo(df, combinacion)\n",
    "    hist = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Evaluacion del modelo por empresa para cada cliente de la empresa\n",
    "    for file in clientes:\n",
    "        path = f'./data/horizontal/{empresa}/{file}'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "        res = hist.model.evaluate(X_val_act, y_val_act, verbose=0)\n",
    "        \n",
    "        tp = res[2]\n",
    "        tn = res[3]\n",
    "        fp = res[4]\n",
    "        fn = res[5]\n",
    "        \n",
    "        cliente_res = {\n",
    "            \"empresa\": empresa,\n",
    "            \"cliente\": re.search(\"cliente_(\\d{1,2}).csv\", file).group(1),\n",
    "            \"tp\": tp,\n",
    "            \"tn\": tn,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn\n",
    "        }\n",
    "    \n",
    "        print(cliente_res)\n",
    "        results = results.append(cliente_res, ignore_index=True)\n",
    "    \n",
    "results.to_csv(\"./results/resultados-modelos-empresa.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empresa v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando empresa_1...\n",
      "{'empresa': 'empresa_1', 'cliente': '12', 'tp': 142.0, 'tn': 87.0, 'fp': 1.0, 'fn': 14.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '13', 'tp': 141.0, 'tn': 75.0, 'fp': 17.0, 'fn': 9.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '14', 'tp': 111.0, 'tn': 64.0, 'fp': 16.0, 'fn': 49.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '15', 'tp': 100.0, 'tn': 110.0, 'fp': 30.0, 'fn': 19.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '18', 'tp': 101.0, 'tn': 94.0, 'fp': 18.0, 'fn': 36.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '3', 'tp': 115.0, 'tn': 79.0, 'fp': 18.0, 'fn': 49.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '4', 'tp': 263.0, 'tn': 143.0, 'fp': 50.0, 'fn': 45.0}\n",
      "{'empresa': 'empresa_1', 'cliente': '5', 'tp': 232.0, 'tn': 151.0, 'fp': 48.0, 'fn': 70.0}\n",
      "Entrenando empresa_2...\n",
      "Restoring model weights from the end of the best epoch: 125.\n",
      "Epoch 00145: early stopping\n",
      "{'empresa': 'empresa_2', 'cliente': '17', 'tp': 43.0, 'tn': 190.0, 'fp': 3.0, 'fn': 16.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '2', 'tp': 21.0, 'tn': 186.0, 'fp': 27.0, 'fn': 21.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '20', 'tp': 50.0, 'tn': 176.0, 'fp': 12.0, 'fn': 17.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '21', 'tp': 52.0, 'tn': 151.0, 'fp': 8.0, 'fn': 26.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '8', 'tp': 35.0, 'tn': 171.0, 'fp': 17.0, 'fn': 38.0}\n",
      "{'empresa': 'empresa_2', 'cliente': '9', 'tp': 30.0, 'tn': 169.0, 'fp': 5.0, 'fn': 43.0}\n",
      "Entrenando empresa_3...\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "Epoch 00062: early stopping\n",
      "{'empresa': 'empresa_3', 'cliente': '1', 'tp': 206.0, 'tn': 18.0, 'fp': 3.0, 'fn': 26.0}\n",
      "{'empresa': 'empresa_3', 'cliente': '10', 'tp': 216.0, 'tn': 12.0, 'fp': 26.0, 'fn': 8.0}\n",
      "{'empresa': 'empresa_3', 'cliente': '11', 'tp': 199.0, 'tn': 9.0, 'fp': 29.0, 'fn': 17.0}\n",
      "{'empresa': 'empresa_3', 'cliente': '16', 'tp': 209.0, 'tn': 15.0, 'fp': 39.0, 'fn': 1.0}\n",
      "{'empresa': 'empresa_3', 'cliente': '19', 'tp': 231.0, 'tn': 11.0, 'fp': 22.0, 'fn': 0.0}\n",
      "{'empresa': 'empresa_3', 'cliente': '6', 'tp': 219.0, 'tn': 0.0, 'fp': 39.0, 'fn': 0.0}\n",
      "{'empresa': 'empresa_3', 'cliente': '7', 'tp': 171.0, 'tn': 30.0, 'fp': 40.0, 'fn': 12.0}\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "results = pd.DataFrame(columns=['empresa', 'cliente', 'tp', 'tn', 'fp', 'fn'])\n",
    "\n",
    "empresas = [\"empresa_1\", \"empresa_2\", \"empresa_3\"]\n",
    "base_path = \"./data/horizontal_v2\"\n",
    "\n",
    "for empresa in empresas:\n",
    "    print(f\"Entrenando {empresa}...\")\n",
    "    clientes = os.listdir(f\"{base_path}/{empresa}/\")\n",
    "    \n",
    "    # Dataset de todos los clientes de la empresa\n",
    "    X_train, X_val, y_train, y_val = prepare_model_data(f'{base_path}/{empresa}/{clientes[0]}')\n",
    "    \n",
    "    for file in clientes[1:]:\n",
    "        path = f'{base_path}/{empresa}/{file}'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "\n",
    "        X_train = np.vstack((X_train, X_train_act))\n",
    "        X_val = np.vstack((X_val, X_val_act))\n",
    "        y_train = np.concatenate((y_train, y_train_act))\n",
    "        y_val = np.concatenate((y_val, y_val_act))\n",
    "    \n",
    "    # Entrenamiento del modelo de la empresa\n",
    "    combinacion = 4\n",
    "    model = generar_modelo(df, combinacion)\n",
    "    hist = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Evaluacion del modelo por empresa para cada cliente de la empresa\n",
    "    for file in clientes:\n",
    "        path = f'{base_path}/{empresa}/{file}'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "        res = hist.model.evaluate(X_val_act, y_val_act, verbose=0)\n",
    "        \n",
    "        tp = res[2]\n",
    "        tn = res[3]\n",
    "        fp = res[4]\n",
    "        fn = res[5]\n",
    "    \n",
    "        cliente_res = {\n",
    "            \"empresa\": empresa,\n",
    "            \"cliente\": re.search(\"cliente_(\\d{1,2}).csv\", file).group(1),\n",
    "            \"tp\": tp,\n",
    "            \"tn\": tn,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn\n",
    "        }\n",
    "    \n",
    "        print(cliente_res)\n",
    "        results = results.append(cliente_res, ignore_index=True)\n",
    "    \n",
    "results.to_csv(\"./results/resultados-modelos-empresa_v2.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empresa v3 con clientes desconocidos\n",
    "\n",
    "Se entrena el modelo con los clientes de la empresa:\n",
    "\n",
    "- Se mide el rendimiento para el conjunto test de los clientes\n",
    "\n",
    "- Se mide el rendimiento para los clientes ajenos a la empresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientes_distr = {\n",
    "    \"empresa_1\": {3,4,5,12,  2,8,  1},\n",
    "    \"empresa_2\": {13,14,    6,7,10,11,16},\n",
    "    \"empresa_3\": {15,18,  9,17,20,21,  19}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando empresa_2...\n",
      "Restoring model weights from the end of the best epoch: 128.\n",
      "Epoch 00148: early stopping\n",
      "{'empresa': 'empresa_2', 'cliente': 1, 'UC?': False, 'tp': 179.0, 'tn': 17.0, 'fp': 4.0, 'fn': 53.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 2, 'UC?': False, 'tp': 41.0, 'tn': 30.0, 'fp': 183.0, 'fn': 1.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 3, 'UC?': False, 'tp': 141.0, 'tn': 22.0, 'fp': 75.0, 'fn': 23.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 4, 'UC?': False, 'tp': 290.0, 'tn': 58.0, 'fp': 135.0, 'fn': 18.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 5, 'UC?': False, 'tp': 278.0, 'tn': 8.0, 'fp': 191.0, 'fn': 24.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 6, 'UC?': True, 'tp': 218.0, 'tn': 4.0, 'fp': 35.0, 'fn': 1.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 7, 'UC?': True, 'tp': 175.0, 'tn': 30.0, 'fp': 40.0, 'fn': 8.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 8, 'UC?': False, 'tp': 73.0, 'tn': 3.0, 'fp': 185.0, 'fn': 0.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 9, 'UC?': False, 'tp': 70.0, 'tn': 10.0, 'fp': 164.0, 'fn': 3.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 10, 'UC?': True, 'tp': 209.0, 'tn': 15.0, 'fp': 23.0, 'fn': 15.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 11, 'UC?': True, 'tp': 191.0, 'tn': 18.0, 'fp': 20.0, 'fn': 25.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 12, 'UC?': False, 'tp': 147.0, 'tn': 62.0, 'fp': 26.0, 'fn': 9.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 13, 'UC?': True, 'tp': 146.0, 'tn': 67.0, 'fp': 25.0, 'fn': 4.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 14, 'UC?': True, 'tp': 139.0, 'tn': 49.0, 'fp': 31.0, 'fn': 21.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 15, 'UC?': False, 'tp': 114.0, 'tn': 49.0, 'fp': 91.0, 'fn': 5.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 16, 'UC?': True, 'tp': 202.0, 'tn': 25.0, 'fp': 29.0, 'fn': 8.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 17, 'UC?': False, 'tp': 57.0, 'tn': 20.0, 'fp': 173.0, 'fn': 2.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 18, 'UC?': False, 'tp': 126.0, 'tn': 32.0, 'fp': 80.0, 'fn': 11.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 19, 'UC?': False, 'tp': 205.0, 'tn': 14.0, 'fp': 19.0, 'fn': 26.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 20, 'UC?': False, 'tp': 61.0, 'tn': 32.0, 'fp': 156.0, 'fn': 6.0}\n",
      "{'empresa': 'empresa_2', 'cliente': 21, 'UC?': False, 'tp': 74.0, 'tn': 17.0, 'fp': 142.0, 'fn': 4.0}\n",
      "Entrenando empresa_3...\n",
      "Restoring model weights from the end of the best epoch: 127.\n",
      "Epoch 00147: early stopping\n",
      "{'empresa': 'empresa_3', 'cliente': 1, 'UC?': False, 'tp': 113.0, 'tn': 20.0, 'fp': 1.0, 'fn': 119.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 2, 'UC?': False, 'tp': 28.0, 'tn': 142.0, 'fp': 71.0, 'fn': 14.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 3, 'UC?': False, 'tp': 71.0, 'tn': 73.0, 'fp': 24.0, 'fn': 93.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 4, 'UC?': False, 'tp': 220.0, 'tn': 154.0, 'fp': 39.0, 'fn': 88.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 5, 'UC?': False, 'tp': 141.0, 'tn': 165.0, 'fp': 34.0, 'fn': 161.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 6, 'UC?': False, 'tp': 49.0, 'tn': 39.0, 'fp': 0.0, 'fn': 170.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 7, 'UC?': False, 'tp': 65.0, 'tn': 59.0, 'fp': 11.0, 'fn': 118.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 8, 'UC?': False, 'tp': 12.0, 'tn': 163.0, 'fp': 25.0, 'fn': 61.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 9, 'UC?': True, 'tp': 35.0, 'tn': 153.0, 'fp': 21.0, 'fn': 38.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 10, 'UC?': False, 'tp': 104.0, 'tn': 31.0, 'fp': 7.0, 'fn': 120.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 11, 'UC?': False, 'tp': 110.0, 'tn': 25.0, 'fp': 13.0, 'fn': 106.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 12, 'UC?': False, 'tp': 96.0, 'tn': 61.0, 'fp': 27.0, 'fn': 60.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 13, 'UC?': False, 'tp': 119.0, 'tn': 58.0, 'fp': 34.0, 'fn': 31.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 14, 'UC?': False, 'tp': 90.0, 'tn': 73.0, 'fp': 7.0, 'fn': 70.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 15, 'UC?': True, 'tp': 93.0, 'tn': 124.0, 'fp': 16.0, 'fn': 26.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 16, 'UC?': False, 'tp': 100.0, 'tn': 46.0, 'fp': 8.0, 'fn': 110.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 17, 'UC?': True, 'tp': 48.0, 'tn': 180.0, 'fp': 13.0, 'fn': 11.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 18, 'UC?': True, 'tp': 102.0, 'tn': 112.0, 'fp': 0.0, 'fn': 35.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 19, 'UC?': True, 'tp': 176.0, 'tn': 22.0, 'fp': 11.0, 'fn': 55.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 20, 'UC?': True, 'tp': 48.0, 'tn': 163.0, 'fp': 25.0, 'fn': 19.0}\n",
      "{'empresa': 'empresa_3', 'cliente': 21, 'UC?': True, 'tp': 60.0, 'tn': 146.0, 'fp': 13.0, 'fn': 18.0}\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "results = pd.DataFrame(columns=['empresa', 'cliente', 'UC?', 'tp', 'tn', 'fp', 'fn'])\n",
    "\n",
    "empresas = [\"empresa_1\", \"empresa_2\", \"empresa_3\"]\n",
    "\n",
    "clientes_distr = {\n",
    "    \"empresa_1\": {3,4,5,12,  2,8,  1},\n",
    "    \"empresa_2\": {13,14,    6,7,10,11,16},\n",
    "    \"empresa_3\": {15,18,  9,17,20,21,  19}\n",
    "}\n",
    "\n",
    "base_path = \"./data/horizontal_v3\"\n",
    "\n",
    "for empresa in empresas:\n",
    "    print(f\"Entrenando {empresa}...\")\n",
    "    clientes = os.listdir(f\"{base_path}/{empresa}/\")\n",
    "    \n",
    "    # Dataset de todos los clientes de la empresa\n",
    "    X_train, X_val, y_train, y_val = prepare_model_data(f'{base_path}/{empresa}/{clientes[0]}')\n",
    "    \n",
    "    for file in clientes[1:]:\n",
    "        path = f'{base_path}/{empresa}/{file}'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "\n",
    "        X_train = np.vstack((X_train, X_train_act))\n",
    "        X_val = np.vstack((X_val, X_val_act))\n",
    "        y_train = np.concatenate((y_train, y_train_act))\n",
    "        y_val = np.concatenate((y_val, y_val_act))\n",
    "    \n",
    "    # Entrenamiento del modelo de la empresa\n",
    "    combinacion = 4\n",
    "    model = generar_modelo(df, combinacion)\n",
    "    hist = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Evaluacion del modelo por empresa para cada cliente de la empresa\n",
    "    for cid in range(1,22):\n",
    "        path = f'./data/centralizado/cliente_{cid}.csv'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "        res = hist.model.evaluate(X_val_act, y_val_act, verbose=0)\n",
    "        \n",
    "        tp = res[2]\n",
    "        tn = res[3]\n",
    "        fp = res[4]\n",
    "        fn = res[5]\n",
    "    \n",
    "        cliente_res = {\n",
    "            \"empresa\": empresa,\n",
    "            \"cliente\": cid,\n",
    "            \"UC?\": cid in clientes_distr[empresa],\n",
    "            \"tp\": tp,\n",
    "            \"tn\": tn,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn\n",
    "        }\n",
    "    \n",
    "        print(cliente_res)\n",
    "        results = results.append(cliente_res, ignore_index=True)\n",
    "    \n",
    "results.to_csv(\"./results/resultados-modelos-empresa_v3.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global/Centralizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'empresa': 2, 'cliente': 1, 'tp': 176.0, 'tn': 20.0, 'fp': 1.0, 'fn': 56.0}\n",
      "{'empresa': 1, 'cliente': 2, 'tp': 37.0, 'tn': 108.0, 'fp': 105.0, 'fn': 5.0}\n",
      "{'empresa': 2, 'cliente': 3, 'tp': 118.0, 'tn': 70.0, 'fp': 27.0, 'fn': 46.0}\n",
      "{'empresa': 1, 'cliente': 4, 'tp': 258.0, 'tn': 127.0, 'fp': 66.0, 'fn': 50.0}\n",
      "{'empresa': 2, 'cliente': 5, 'tp': 237.0, 'tn': 136.0, 'fp': 63.0, 'fn': 65.0}\n",
      "{'empresa': 1, 'cliente': 6, 'tp': 192.0, 'tn': 12.0, 'fp': 27.0, 'fn': 27.0}\n",
      "{'empresa': 2, 'cliente': 7, 'tp': 113.0, 'tn': 46.0, 'fp': 24.0, 'fn': 70.0}\n",
      "{'empresa': 1, 'cliente': 8, 'tp': 42.0, 'tn': 154.0, 'fp': 34.0, 'fn': 31.0}\n",
      "{'empresa': 2, 'cliente': 9, 'tp': 52.0, 'tn': 115.0, 'fp': 59.0, 'fn': 21.0}\n",
      "{'empresa': 1, 'cliente': 10, 'tp': 175.0, 'tn': 13.0, 'fp': 25.0, 'fn': 49.0}\n",
      "{'empresa': 2, 'cliente': 11, 'tp': 159.0, 'tn': 26.0, 'fp': 12.0, 'fn': 57.0}\n",
      "{'empresa': 1, 'cliente': 12, 'tp': 142.0, 'tn': 84.0, 'fp': 4.0, 'fn': 14.0}\n",
      "{'empresa': 2, 'cliente': 13, 'tp': 144.0, 'tn': 61.0, 'fp': 31.0, 'fn': 6.0}\n",
      "{'empresa': 1, 'cliente': 14, 'tp': 111.0, 'tn': 68.0, 'fp': 12.0, 'fn': 49.0}\n",
      "{'empresa': 2, 'cliente': 15, 'tp': 98.0, 'tn': 103.0, 'fp': 37.0, 'fn': 21.0}\n",
      "{'empresa': 1, 'cliente': 16, 'tp': 180.0, 'tn': 34.0, 'fp': 20.0, 'fn': 30.0}\n",
      "{'empresa': 2, 'cliente': 17, 'tp': 52.0, 'tn': 131.0, 'fp': 62.0, 'fn': 7.0}\n",
      "{'empresa': 1, 'cliente': 18, 'tp': 108.0, 'tn': 102.0, 'fp': 10.0, 'fn': 29.0}\n",
      "{'empresa': 2, 'cliente': 19, 'tp': 184.0, 'tn': 19.0, 'fp': 14.0, 'fn': 47.0}\n",
      "{'empresa': 1, 'cliente': 20, 'tp': 52.0, 'tn': 124.0, 'fp': 64.0, 'fn': 15.0}\n",
      "{'empresa': 2, 'cliente': 21, 'tp': 66.0, 'tn': 127.0, 'fp': 32.0, 'fn': 12.0}\n"
     ]
    }
   ],
   "source": [
    "e1 = os.listdir(\"./data/horizontal/empresa_1/\")\n",
    "e2 = os.listdir(\"./data/horizontal/empresa_2/\")\n",
    "\n",
    "# Dataset de todos los clientes\n",
    "X_train, X_val, y_train, y_val = prepare_model_data(f'./data/horizontal/empresa_2/{e2[0]}')\n",
    "\n",
    "for file in e1:\n",
    "    path = f'./data/horizontal/empresa_1/{file}'\n",
    "    X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "    X_train = np.vstack((X_train, X_train_act))\n",
    "    X_val = np.vstack((X_val, X_val_act))\n",
    "    y_train = np.concatenate((y_train, y_train_act))\n",
    "    y_val = np.concatenate((y_val, y_val_act))\n",
    "    \n",
    "for file in e2[1:]:\n",
    "    path = f'./data/horizontal/empresa_2/{file}'\n",
    "    X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "    X_train = np.vstack((X_train, X_train_act))\n",
    "    X_val = np.vstack((X_val, X_val_act))\n",
    "    y_train = np.concatenate((y_train, y_train_act))\n",
    "    y_val = np.concatenate((y_val, y_val_act))\n",
    "\n",
    "# Entrenamiento de modelo centralizado\n",
    "combinacion = 4\n",
    "model = generar_modelo(df, combinacion)\n",
    "hist = train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Evaluacion del modelo por empresa para cada cliente de la empresa\n",
    "results = pd.DataFrame(columns=['empresa', 'cliente', 'tp', 'tn', 'fp', 'fn'])\n",
    "for cid in range(1,22):\n",
    "    base_path = \"./data/horizontal/\"\n",
    "    path = f\"{base_path}empresa_{(int(cid)%2)+1}/cliente_{cid}.csv\"\n",
    "    \n",
    "    X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "    res = hist.model.evaluate(X_val_act, y_val_act, verbose=0)\n",
    "    \n",
    "    tp = res[2]\n",
    "    tn = res[3]\n",
    "    fp = res[4]\n",
    "    fn = res[5]\n",
    "\n",
    "    centralizado_res = {\n",
    "        \"empresa\": (int(cid)%2)+1,\n",
    "        \"cliente\": cid,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn\n",
    "    }\n",
    "\n",
    "    print(centralizado_res)\n",
    "    results = results.append(centralizado_res, ignore_index=True)\n",
    "    \n",
    "results.to_csv(\"./results/resultados-modelo-centralizado.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralizado con cliente desconocido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_dataset_varios_clientes(clientes):\n",
    "    base_path = \"./data/centralizado\"\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = prepare_model_data(f'{base_path}/cliente_{clientes[0]}.csv')\n",
    "    \n",
    "    for cid in clientes[1:]:\n",
    "        path = f'{base_path}/cliente_{cid}.csv'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "        X_train = np.vstack((X_train, X_train_act))\n",
    "        X_val = np.vstack((X_val, X_val_act))\n",
    "        y_train = np.concatenate((y_train, y_train_act))\n",
    "        y_val = np.concatenate((y_val, y_val_act))\n",
    "        \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid: 1 - {'cliente': 1, 'tp': 2410.0, 'tn': 1871.0, 'fp': 517.0, 'fn': 761.0, 'tp_c': 137.0, 'tn_c': 19.0, 'fp_c': 2.0, 'fn_c': 95.0}\n",
      "cid: 2 - {'cliente': 2, 'tp': 2759.0, 'tn': 1543.0, 'fp': 653.0, 'fn': 602.0, 'tp_c': 37.0, 'tn_c': 102.0, 'fp_c': 111.0, 'fn_c': 5.0}\n",
      "cid: 3 - {'cliente': 3, 'tp': 2542.0, 'tn': 1691.0, 'fp': 621.0, 'fn': 697.0, 'tp_c': 101.0, 'tn_c': 56.0, 'fp_c': 41.0, 'fn_c': 63.0}\n",
      "cid: 4 - {'cliente': 4, 'tp': 2374.0, 'tn': 1674.0, 'fp': 542.0, 'fn': 721.0, 'tp_c': 247.0, 'tn_c': 101.0, 'fp_c': 92.0, 'fn_c': 61.0}\n",
      "cid: 5 - {'cliente': 5, 'tp': 2376.0, 'tn': 1673.0, 'fp': 537.0, 'fn': 725.0, 'tp_c': 185.0, 'tn_c': 118.0, 'fp_c': 81.0, 'fn_c': 117.0}\n",
      "cid: 6 - {'cliente': 6, 'tp': 2423.0, 'tn': 1776.0, 'fp': 594.0, 'fn': 761.0, 'tp_c': 53.0, 'tn_c': 36.0, 'fp_c': 3.0, 'fn_c': 166.0}\n",
      "cid: 7 - {'cliente': 7, 'tp': 2479.0, 'tn': 1789.0, 'fp': 550.0, 'fn': 741.0, 'tp_c': 91.0, 'tn_c': 50.0, 'fp_c': 20.0, 'fn_c': 92.0}\n",
      "cid: 8 - {'cliente': 8, 'tp': 2602.0, 'tn': 1612.0, 'fp': 609.0, 'fn': 728.0, 'tp_c': 18.0, 'tn_c': 87.0, 'fp_c': 101.0, 'fn_c': 55.0}\n",
      "cid: 9 - {'cliente': 9, 'tp': 2643.0, 'tn': 1624.0, 'fp': 611.0, 'fn': 687.0, 'tp_c': 54.0, 'tn_c': 84.0, 'fp_c': 90.0, 'fn_c': 19.0}\n",
      "cid: 10 - {'cliente': 10, 'tp': 2442.0, 'tn': 1785.0, 'fp': 586.0, 'fn': 737.0, 'tp_c': 138.0, 'tn_c': 24.0, 'fp_c': 14.0, 'fn_c': 86.0}\n",
      "cid: 11 - {'cliente': 11, 'tp': 2499.0, 'tn': 1749.0, 'fp': 622.0, 'fn': 688.0, 'tp_c': 143.0, 'tn_c': 25.0, 'fp_c': 13.0, 'fn_c': 73.0}\n",
      "cid: 12 - {'cliente': 12, 'tp': 2505.0, 'tn': 1665.0, 'fp': 656.0, 'fn': 742.0, 'tp_c': 135.0, 'tn_c': 76.0, 'fp_c': 12.0, 'fn_c': 21.0}\n",
      "cid: 13 - {'cliente': 13, 'tp': 2587.0, 'tn': 1639.0, 'fp': 678.0, 'fn': 666.0, 'tp_c': 132.0, 'tn_c': 39.0, 'fp_c': 53.0, 'fn_c': 18.0}\n",
      "cid: 14 - {'cliente': 14, 'tp': 2444.0, 'tn': 1778.0, 'fp': 551.0, 'fn': 799.0, 'tp_c': 102.0, 'tn_c': 69.0, 'fp_c': 11.0, 'fn_c': 58.0}\n",
      "cid: 15 - {'cliente': 15, 'tp': 2616.0, 'tn': 1576.0, 'fp': 693.0, 'fn': 668.0, 'tp_c': 104.0, 'tn_c': 87.0, 'fp_c': 53.0, 'fn_c': 15.0}\n",
      "cid: 16 - {'cliente': 16, 'tp': 2373.0, 'tn': 1821.0, 'fp': 534.0, 'fn': 820.0, 'tp_c': 151.0, 'tn_c': 34.0, 'fp_c': 20.0, 'fn_c': 59.0}\n",
      "cid: 17 - {'cliente': 17, 'tp': 2676.0, 'tn': 1566.0, 'fp': 650.0, 'fn': 668.0, 'tp_c': 54.0, 'tn_c': 68.0, 'fp_c': 125.0, 'fn_c': 5.0}\n",
      "cid: 18 - {'cliente': 18, 'tp': 2565.0, 'tn': 1694.0, 'fp': 603.0, 'fn': 701.0, 'tp_c': 101.0, 'tn_c': 77.0, 'fp_c': 35.0, 'fn_c': 36.0}\n",
      "cid: 19 - {'cliente': 19, 'tp': 2419.0, 'tn': 1805.0, 'fp': 571.0, 'fn': 753.0, 'tp_c': 135.0, 'tn_c': 22.0, 'fp_c': 11.0, 'fn_c': 96.0}\n",
      "cid: 20 - {'cliente': 20, 'tp': 2650.0, 'tn': 1578.0, 'fp': 643.0, 'fn': 686.0, 'tp_c': 43.0, 'tn_c': 87.0, 'fp_c': 101.0, 'fn_c': 24.0}\n",
      "Restoring model weights from the end of the best epoch: 117.\n",
      "Epoch 00137: early stopping\n",
      "cid: 21 - {'cliente': 21, 'tp': 2568.0, 'tn': 1647.0, 'fp': 603.0, 'fn': 757.0, 'tp_c': 65.0, 'tn_c': 123.0, 'fp_c': 36.0, 'fn_c': 13.0}\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['cliente', 'tp', 'tn', 'fp', 'fn', 'tp_c', 'tn_c', 'fp_c', 'fn_c'])\n",
    "\n",
    "CLIENTS_IDS = list(range(1,22))\n",
    "\n",
    "for cid in CLIENTS_IDS:\n",
    "    # Se carga el dataset de todos los clientes menos el actual\n",
    "    actual_clients = list(range(1,22))\n",
    "    actual_clients.remove(cid)\n",
    "    X_train, X_val, y_train, y_val = cargar_dataset_varios_clientes(actual_clients)\n",
    "    \n",
    "    seed(1)\n",
    "    set_random_seed(2)\n",
    "    \n",
    "    # Entrenamiento de modelo centralizado\n",
    "    combinacion = 4\n",
    "    model = generar_modelo(df, combinacion)\n",
    "    hist = train_model(model, X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # Evaluar para los clientes conocidos\n",
    "    res = hist.model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    tp = res[2]\n",
    "    tn = res[3]\n",
    "    fp = res[4]\n",
    "    fn = res[5]\n",
    "    \n",
    "    # Evaluar para el cliente nuevo\n",
    "    X_train_c, X_val_c, y_train_c, y_val_c = prepare_model_data(f'./data/centralizado/cliente_{cid}.csv')\n",
    "    res_c = hist.model.evaluate(X_val_c, y_val_c, verbose=0)\n",
    "    \n",
    "    tp_c = res_c[2]\n",
    "    tn_c = res_c[3]\n",
    "    fp_c = res_c[4]\n",
    "    fn_c = res_c[5]\n",
    "    \n",
    "    centralizado_res = {\n",
    "        \"cliente\": cid,\n",
    "        \"tp\": tp,\n",
    "        \"tn\": tn,\n",
    "        \"fp\": fp,\n",
    "        \"fn\": fn,\n",
    "        \"tp_c\": tp_c,\n",
    "        \"tn_c\": tn_c,\n",
    "        \"fp_c\": fp_c,\n",
    "        \"fn_c\": fn_c\n",
    "    }\n",
    "\n",
    "    print(f'cid: {cid} - {centralizado_res}')\n",
    "    results = results.append(centralizado_res, ignore_index=True)\n",
    "    \n",
    "results.to_csv(\"./results/resultados-modelo-centralizado-new-client.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
