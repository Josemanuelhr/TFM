{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9725de4-861a-46c3-8c6c-e9104905202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Make TensorFlow logs less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "from flwr.common.logger import log\n",
    "from logging import INFO\n",
    "from csv import writer\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "\n",
    "from tensorflow.keras.metrics import Precision, Recall, TrueNegatives, TruePositives, FalsePositives, FalseNegatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fcfb69-5c98-47e2-aafc-2f16d07f1318",
   "metadata": {},
   "source": [
    "# Funcionalidad de la generación de los conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f001b623-d1de-465e-a336-9078debe716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_IDS = list(range(1,21+1))\n",
    "\n",
    "CONDUCTORES_IDS = {\n",
    "    1: [3,4,5,12,  2,8,  1],\n",
    "    2: [13,14,    6,7,10,11,16],\n",
    "    3: [15,18,  9,17,20,21,  19]\n",
    "}\n",
    "\n",
    "# Parametros:\n",
    "    # tam: numero de sujetos que debe haber en las combinaciones generadas\n",
    "# Retorna:\n",
    "    # Lista de listas, cada lista se corresponde con una combinacion diferente de tamaño n_desconocidos\n",
    "def generar_combinaciones(tam):\n",
    "    return list(combinations(ALL_IDS, tam))\n",
    "\n",
    "# Parametros:\n",
    "    # comb: lista con los conductores de la combinacion\n",
    "# Retorna:\n",
    "    # True: si hay al menos uno de cada empresa\n",
    "    # False: en caso contrario\n",
    "def uno_por_empresa(comb):\n",
    "    conds = {\n",
    "        1: False,\n",
    "        2: False,\n",
    "        3: False\n",
    "    }\n",
    "    \n",
    "    for cid in comb:\n",
    "        for empid in CONDUCTORES_IDS:\n",
    "            if(cid in CONDUCTORES_IDS[empid]):\n",
    "                conds[empid] = True\n",
    "    \n",
    "    return conds[1] and conds[2] and conds[3]\n",
    "\n",
    "def subset_combinaciones_validas(combs, n):\n",
    "    seleccionadas = []\n",
    "    idx_comprobados = []\n",
    "    n_seleccionadas = 0\n",
    "    \n",
    "    seed(123)\n",
    "    \n",
    "    while (n_seleccionadas<n):\n",
    "        idx = int(np.random.randint(0, len(combs), 1))\n",
    "        \n",
    "        if (idx not in idx_comprobados):\n",
    "            comb = combs[idx]\n",
    "            \n",
    "            if (uno_por_empresa(comb)):\n",
    "                seleccionadas.append(comb)\n",
    "                n_seleccionadas += 1\n",
    "                \n",
    "        idx_comprobados.append(idx)\n",
    "            \n",
    "    return seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c5875d4-db76-4ab0-850f-4f1bc4f475ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conocidos: 20; desconocidos: 1 => Combinaciones a estudiar 21 de 21\n",
      "conocidos: 19; desconocidos: 2 => Combinaciones a estudiar 210 de 210\n",
      "conocidos: 18; desconocidos: 3 => Combinaciones a estudiar 1330 de 1330\n",
      "conocidos: 17; desconocidos: 4 => Combinaciones a estudiar 5985 de 5985\n",
      "conocidos: 16; desconocidos: 5 => Combinaciones a estudiar 20349 de 20349\n",
      "conocidos: 15; desconocidos: 6 => Combinaciones a estudiar 54264 de 54264\n",
      "conocidos: 14; desconocidos: 7 => Combinaciones a estudiar 116277 de 116280\n",
      "conocidos: 13; desconocidos: 8 => Combinaciones a estudiar 203448 de 203490\n",
      "conocidos: 12; desconocidos: 9 => Combinaciones a estudiar 293657 de 293930\n",
      "conocidos: 11; desconocidos: 10 => Combinaciones a estudiar 351624 de 352716\n",
      "conocidos: 10; desconocidos: 11 => Combinaciones a estudiar 349713 de 352716\n",
      "conocidos: 9; desconocidos: 12 => Combinaciones a estudiar 287924 de 293930\n",
      "conocidos: 8; desconocidos: 13 => Combinaciones a estudiar 194481 de 203490\n",
      "conocidos: 7; desconocidos: 14 => Combinaciones a estudiar 105987 de 116280\n"
     ]
    }
   ],
   "source": [
    "for n_desconocidos in range(1,14+1):\n",
    "    combs = generar_combinaciones(21-n_desconocidos)\n",
    "    combs_totales = 0\n",
    "    combs_probar = 0\n",
    "    for comb in combs:\n",
    "        combs_totales += 1\n",
    "        if (uno_por_empresa(comb)):\n",
    "            # FL\n",
    "            combs_probar += 1\n",
    "    print(f\"conocidos: {21-n_desconocidos}; desconocidos: {n_desconocidos} => Combinaciones a estudiar {combs_probar} de {combs_totales}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3318d1-196a-49f0-bb3b-39a43aee32d0",
   "metadata": {},
   "source": [
    "# Funcionalidad del FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4db9176-0d3d-49b2-a8d1-255106832f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, model, x_train, y_train, x_val, y_val) -> None:\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_val, self.y_val = x_val, y_val\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        \n",
    "        seed(1)\n",
    "        set_random_seed(2)\n",
    "        \n",
    "        self.model.fit(self.x_train, self.y_train,\n",
    "                       epochs=int(config[\"epochs\"]),\n",
    "                       batch_size=32,\n",
    "                       verbose=0)\n",
    "        \n",
    "        return self.model.get_weights(), len(self.x_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        \n",
    "        loss, acc = self.model.evaluate(self.x_val, self.y_val, verbose=0)\n",
    "        \n",
    "        return loss, len(self.x_val), {\"accuracy\": acc, \"client\": self.cid}\n",
    "    \n",
    "''' FUNCION PARA CARGAR LOS DATOS DE UN CLIENTE EN PARTICULAR '''\n",
    "def prepare_model_data(client_file):\n",
    "    df = pd.read_csv(client_file)\n",
    "    \n",
    "    train, test = train_test_split(df, test_size=0.30, random_state=42)\n",
    "    \n",
    "    X_train = train[['psd_delta', 'psd_theta', 'psd_alpha', 'psd_beta', 'psd_gamma','eog_blinks', 'eog_var']]\n",
    "    X_test = test[['psd_delta', 'psd_theta', 'psd_alpha', 'psd_beta', 'psd_gamma','eog_blinks', 'eog_var']]\n",
    "    y_train = train['y_class']\n",
    "    y_test = test['y_class']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "''' FUNCION PARA CARGAR LOS DATOS DE UNA EMPRESA '''\n",
    "def get_data_empresa(empresa):\n",
    "    base_path = \"./data/horizontal_v3\"\n",
    "    # Cargar y procesar datos de todos sus clientes\n",
    "    clientes = os.listdir(f\"{base_path}/{empresa}/\")\n",
    "    \n",
    "    for client_id in UNSEEN_CLIENTS:\n",
    "        try:\n",
    "            clientes.remove(f'cliente_{client_id}.csv')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = prepare_model_data(f'{base_path}/{empresa}/{clientes[0]}')\n",
    "    \n",
    "    # Debe funcionar aunq exista solo clientes[0]\n",
    "    for file in clientes[1:]:\n",
    "        path = f'{base_path}/{empresa}/{file}'\n",
    "        X_train_act, X_test_act, y_train_act, y_test_act = prepare_model_data(path)\n",
    "\n",
    "        X_train = np.vstack((X_train, X_train_act))\n",
    "        X_test = np.vstack((X_test, X_test_act))\n",
    "        y_train = np.concatenate((y_train, y_train_act))\n",
    "        y_test = np.concatenate((y_test, y_test_act))\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def client_fn(cid: str) -> fl.client.Client:\n",
    "    # Model best hyperparameters (Ver notebook Hito0-Optimizacion-Baseline)\n",
    "    neurons = 36\n",
    "    activation = \"relu\"\n",
    "    learning_rate = 0.180165\n",
    "    optimizer = Adadelta(learning_rate=learning_rate)\n",
    "    \n",
    "    input_shape = (7,)\n",
    "    \n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(neurons, input_shape=input_shape, activation=activation))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "        \n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Load data partition    \n",
    "    x_train_cid, x_val_cid, y_train_cid, y_val_cid = get_data_empresa(cid)\n",
    "\n",
    "    # Create and return client\n",
    "    return FlowerClient(cid, model, x_train_cid, y_train_cid, x_val_cid, y_val_cid)\n",
    "\n",
    "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
    "    def aggregate_fit(self, rnd, results, failures):\n",
    "        aggregated_weights = super().aggregate_fit(rnd, results, failures)\n",
    "        \n",
    "        if aggregated_weights is not None:\n",
    "            # Save aggregated_weights\n",
    "            np.savez(f\"./tmp/hito2-round-{rnd}-weights.npz\", aggregated_weights)\n",
    "            \n",
    "        return aggregated_weights\n",
    "\n",
    "    def aggregate_evaluate(self, rnd, results, failures):\n",
    "        super_result = super().aggregate_evaluate(rnd, results, failures)\n",
    "        \n",
    "        data = {}\n",
    "        for r in results:\n",
    "            acc = r[1].metrics[\"accuracy\"]\n",
    "            client = r[1].metrics[\"client\"]\n",
    "            data[client] = acc\n",
    "        \n",
    "        df = pd.DataFrame(data, index=[0], columns=sorted(data.keys()))\n",
    "        df.to_csv(f\"./results/hito2.csv\", mode='a', index=False, header=False)\n",
    "        \n",
    "        return super_result\n",
    "    \n",
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "neurons = 36\n",
    "activation = \"relu\"\n",
    "learning_rate = 0.180165\n",
    "optimizer = Adadelta(learning_rate=learning_rate)\n",
    "\n",
    "input_shape = (7,)\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(neurons, input_shape=input_shape, activation=activation))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(neurons, activation=activation))\n",
    "model.add(Dense(neurons, activation=activation))\n",
    "model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Get model weights as a list of NumPy ndarray's\n",
    "weights = model.get_weights()\n",
    "# Serialize ndarrays to `Parameters`\n",
    "parameters = fl.common.weights_to_parameters(weights)\n",
    "\n",
    "# Configuracion de parametros para el entrenamiento desde el servidor\n",
    "def fit_config(rnd: int) -> Dict[str, str]:\n",
    "    config = {\n",
    "        \"round\": str(rnd),\n",
    "        \"epochs\": str(1) \n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550503d-e2ef-4b67-9c6e-5e36faa3b4da",
   "metadata": {},
   "source": [
    "# Experimentacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f27d8bd-c009-4f2d-a597-3aeba3ca6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_dataset_varios_clientes(clientes):\n",
    "    base_path = \"./data/centralizado\"\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = prepare_model_data(f'{base_path}/cliente_{clientes[0]}.csv')\n",
    "    \n",
    "    for cid in clientes[1:]:\n",
    "        path = f'{base_path}/cliente_{cid}.csv'\n",
    "        X_train_act, X_val_act, y_train_act, y_val_act = prepare_model_data(path)\n",
    "    \n",
    "        X_train = np.vstack((X_train, X_train_act))\n",
    "        X_val = np.vstack((X_val, X_val_act))\n",
    "        y_train = np.concatenate((y_train, y_train_act))\n",
    "        y_val = np.concatenate((y_val, y_val_act))\n",
    "        \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "def setup_model(weights_path):\n",
    "    neurons = 36\n",
    "    activation = \"relu\"\n",
    "    learning_rate = 0.180165\n",
    "    optimizer = Adadelta(learning_rate=learning_rate)\n",
    "\n",
    "    input_shape = (7,)\n",
    "\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_shape=input_shape, activation=activation))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', TruePositives(), TrueNegatives(), FalsePositives(), FalseNegatives()])\n",
    "    \n",
    "    a = np.load(weights_path, allow_pickle=True)\n",
    "\n",
    "    n_elems = [252, 36,\n",
    "               36, 36, 36, 36,\n",
    "               1296, 36,\n",
    "               1296, 36,\n",
    "               1296, 36,\n",
    "               36, 1]\n",
    "\n",
    "    weights = []\n",
    "\n",
    "    # https://numpy.org/devdocs/reference/generated/numpy.lib.format.html#version-numbering\n",
    "    # En base a la doc sabemos que los datos de interes estan al final, y como deben ser float32 => 4 bytes\n",
    "    # por lo que se toman los n_elementos*4bytes del final\n",
    "\n",
    "    for i, t in enumerate(a[\"arr_0\"][0].tensors):\n",
    "        act = np.frombuffer(t[-n_elems[i]*4:], dtype=np.float32)\n",
    "        weights.append(act)\n",
    "\n",
    "    # Se cambia la forma para que se adapte a la del modelo\n",
    "    weights[0] = weights[0].reshape(7,36)\n",
    "    weights[6] = weights[6].reshape(36,36)\n",
    "    weights[8] = weights[8].reshape(36,36)\n",
    "    weights[10] = weights[10].reshape(36,36)\n",
    "    weights[12] = weights[12].reshape(36,1)\n",
    "\n",
    "    model.set_weights(weights)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_FLmodel(KCs, UCs, rnd):\n",
    "    path = f\"./tmp/hito2-round-{rnd}-weights.npz\"\n",
    "    model = setup_model(path)\n",
    "    \n",
    "    # Evaluar para los clientes conocidos\n",
    "    X_train, X_val, y_train, y_val = cargar_dataset_varios_clientes(KCs)\n",
    "    res = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    tp_k = res[2]\n",
    "    tn_k = res[3]\n",
    "    fp_k = res[4]\n",
    "    fn_k = res[5]\n",
    "    \n",
    "    k_acc = (tp_k+tn_k)/(tp_k+tn_k+fp_k+fn_k)\n",
    "    k_sens = (tp_k)/(tp_k+fn_k)\n",
    "    k_spec = (tn_k)/(tn_k+fp_k)\n",
    "    k_f1 = (tp_k)/( tp_k + (fp_k+fn_k)/2 )\n",
    "    \n",
    "    # Evaluar para los clientes nuevos\n",
    "    X_train, X_val, y_train, y_val = cargar_dataset_varios_clientes(UCs)\n",
    "    res_c = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    tp_u = res_c[2]\n",
    "    tn_u = res_c[3]\n",
    "    fp_u = res_c[4]\n",
    "    fn_u = res_c[5]\n",
    "    \n",
    "    u_acc = (tp_u+tn_u)/(tp_u+tn_u+fp_u+fn_u)\n",
    "    u_sens = (tp_u)/(tp_u+fn_u)\n",
    "    u_spec = (tn_u)/(tn_u+fp_u)\n",
    "    u_f1 = (tp_u)/( tp_u + (fp_u+fn_u)/2 )\n",
    "    \n",
    "    return k_acc, k_sens, k_spec, k_f1, u_acc, u_sens, u_spec, u_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daac77f6-c00d-49d3-93dc-16d5724b981e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLIENTS_IDS = [\"empresa_1\", \"empresa_2\", \"empresa_3\"]\n",
    "\n",
    "# Experimentacion de 1 a 14 conductores desconocidos\n",
    "for n_desconocidos in range(1,14+1):\n",
    "    combs = generar_combinaciones(21-n_desconocidos)\n",
    "    if (n_desconocidos > 1):\n",
    "        combs = subset_combinaciones_validas(combs, 30) # MODIFICAR 30 para aumentar tam de la muestra\n",
    "    \n",
    "    # Se crea el fichero si no existe previamente\n",
    "    if not os.path.exists(f\"./results/hito2_{n_desconocidos}UCs.csv\"):\n",
    "        results_fed = pd.DataFrame(columns=[\"UCs\", \"k_acc\", \"k_sens\", \"k_spec\", \"k_f1\", \"u_acc\", \"u_sens\", \"u_spec\", \"u_f1\"])\n",
    "        results_fed.to_csv(f\"./results/hito2_{n_desconocidos}UCs.csv\", mode='w', index=False, header=True)\n",
    "    \n",
    "    # Se busca si ya hay algun registro\n",
    "    with open(f\"./results/hito2_{n_desconocidos}UCs.csv\", 'r') as f:\n",
    "        start_comb = len(f.readlines())-1 # restandole el header\n",
    "    \n",
    "    # Se comienza/retoma el experimento de n_desconocidos\n",
    "    for comb in combs[start_comb:]:\n",
    "        if (uno_por_empresa(comb)):\n",
    "            global UNSEEN_CLIENTS\n",
    "            UNSEEN_CLIENTS = list(set(ALL_IDS)-set(comb))\n",
    "            \n",
    "            # Fichero para almacenar los resultados de este entrenamiento federado\n",
    "            with open(f\"./results/hito2.csv\", 'w') as f:\n",
    "                csv_writer = writer(f)\n",
    "                csv_writer.writerow([\"empresa_1\", \"empresa_2\", \"empresa_3\"])\n",
    "            \n",
    "            # FL\n",
    "            fl.simulation.start_simulation(\n",
    "                client_fn=client_fn,\n",
    "                clients_ids=CLIENTS_IDS,\n",
    "                client_resources={\"num_cpus\": 6},\n",
    "                num_rounds=5,\n",
    "                strategy=SaveModelStrategy(\n",
    "                    min_available_clients = len(CLIENTS_IDS),\n",
    "                    min_fit_clients = len(CLIENTS_IDS),\n",
    "                    min_eval_clients = len(CLIENTS_IDS),\n",
    "                    on_fit_config_fn = fit_config,\n",
    "                    on_evaluate_config_fn = fit_config,\n",
    "                    accept_failures=False,\n",
    "                    initial_parameters=parameters\n",
    "                ),\n",
    "            )\n",
    "            \n",
    "            # Leer resultados del entrenamiento\n",
    "            df = pd.read_csv('./results/hito2.csv')\n",
    "            df[\"mean\"] = df.mean(numeric_only=True, axis=1)\n",
    "\n",
    "            best_rnd = df[\"mean\"].idxmax()+1\n",
    "            \n",
    "            # Evaluar con los pesos de la mejor ronda tanto para clientes conocidos como desconocidos\n",
    "            k_acc, k_sens, k_spec, k_f1, u_acc, u_sens, u_spec, u_f1 = evaluate_FLmodel(list(comb), UNSEEN_CLIENTS, best_rnd)\n",
    "            \n",
    "            # Almacenar resultados de este entrenamiento\n",
    "            results_fed = pd.DataFrame(columns=[\"UCs\", \"k_acc\", \"k_sens\", \"k_spec\", \"k_f1\", \"u_acc\", \"u_sens\", \"u_spec\", \"u_f1\"])\n",
    "            fed_res = {\n",
    "                \"UCs\": UNSEEN_CLIENTS,\n",
    "                \"k_acc\": k_acc,\n",
    "                \"k_sens\": k_sens,\n",
    "                \"k_spec\": k_spec,\n",
    "                \"k_f1\": k_f1,\n",
    "                \"u_acc\": u_acc,\n",
    "                \"u_sens\": u_sens,\n",
    "                \"u_spec\": u_spec,\n",
    "                \"u_f1\": u_f1\n",
    "            }\n",
    "            \n",
    "            results_fed = results_fed.append(fed_res, ignore_index=True)\n",
    "            results_fed.to_csv(f\"./results/hito2_{n_desconocidos}UCs.csv\", mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7bbd55-e44d-43ae-ad11-580542591283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
